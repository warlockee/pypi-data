{
    "0.2.0": {
        "info": {
            "author": "Unstructured Technologies",
            "author_email": "devops@unstructuredai.io",
            "bugtrack_url": null,
            "classifiers": [
                "Development Status :: 4 - Beta",
                "Intended Audience :: Developers",
                "Intended Audience :: Education",
                "Intended Audience :: Science/Research",
                "License :: OSI Approved :: Apache Software License",
                "Operating System :: OS Independent",
                "Programming Language :: Python :: 3",
                "Programming Language :: Python :: 3.8",
                "Programming Language :: Python :: 3.9",
                "Topic :: Scientific/Engineering :: Artificial Intelligence"
            ],
            "description": "<h3 align=\"center\">\n  <img src=\"img/unstructured_logo.png\" height=\"200\">\n</h3>\n\n<h3 align=\"center\">\n  <p>Open-Source Pre-Processing Tools for Unstructured Data</p>\n</h3>\n\nThe `unstructured-inference` repo contains hosted model inference code for layout parsing models. \nThese models are invoked via API as part of the partitioning bricks in the `unstructured` package.\n\n## Installation\n\n### Package\n\nRequires [`torch>=1.8`](https://pytorch.org/get-started/locally/). Once this is satisfied, run \n`pip install unstructured-inference`.\n\n### Repository\n\nClone the repo and run `make install` to install dependencies.\nRun `make help` for a full list of install options.\n\n## Getting Started\n\nTo get started with the layout parsing model, use the following commands:\n\n```python\nfrom unstructured_inference.inference.layout import DocumentLayout\n\nlayout = DocumentLayout.from_file(\"sample-docs/loremipsum.pdf\")\n\nprint(layout.pages[0].elements)\n```\n\nOnce the model has detected the layout and OCR'd the document, the text extracted from the first \npage of the sample document will be displayed.\nYou can convert a given element to a `dict` by running the `.to_dict()` method.\n\nTo build the Docker container, run `make docker-build`. Note that Apple hardware with an M1 chip \nhas trouble building `Detectron2` on Docker and for best results you should build it on Linux. To \nrun the API locally, use `make start-app-local`. You can stop the API with `make stop-app-local`. \nThe API will run at `http:/localhost:5000`. \nYou can then `POST` a PDF file to the API endpoint to see its layout with the command:\n```\ncurl -X 'POST' 'http://localhost:5000/layout/pdf' -F 'file=@<your_pdf_file>' | jq -C . | less -R\n```\n\nYou can also choose the types of elements you want to return from the output of PDF parsing by \npassing a list of types to the `include_elems` parameter. For example, if you only want to return \n`Text` elements and `Title` elements, you can curl:\n```\ncurl -X 'POST' 'http://localhost:5000/layout/pdf' \\\n-F 'file=@<your_pdf_file>' \\\n-F include_elems=Text \\\n-F include_elems=Title \\\n | jq -C | less -R\n```\nIf you are using an Apple M1 chip, use `make run-app-dev` instead of `make start-app-local` to \nstart the API with hot reloading. The API will run at `http:/localhost:8000`.\n\nView the swagger documentation at `http://localhost:5000/docs`.\n## Security Policy\n\nSee our [security policy](https://github.com/Unstructured-IO/unstructured-inference/security/policy) for\ninformation on how to report security vulnerabilities.\n\n## Learn more\n\n| Section | Description |\n|-|-|\n| [Unstructured Community Github](https://github.com/Unstructured-IO/community) | Information about Unstructured.io community projects  |\n| [Unstructured Github](https://github.com/Unstructured-IO) | Unstructured.io open source repositories |\n| [Company Website](https://unstructured.io) | Unstructured.io product and company info |",
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/Unstructured-IO/unstructured-inference",
            "keywords": "NLP PDF HTML CV XML parsing preprocessing",
            "license": "Apache-2.0",
            "maintainer": "",
            "maintainer_email": "",
            "name": "unstructured-inference",
            "package_url": "https://pypi.org/project/unstructured-inference/",
            "platform": null,
            "project_url": "https://pypi.org/project/unstructured-inference/",
            "project_urls": {
                "Homepage": "https://github.com/Unstructured-IO/unstructured-inference"
            },
            "release_url": "https://pypi.org/project/unstructured-inference/0.2.0/",
            "requires_dist": null,
            "requires_python": ">=3.7.0",
            "summary": "A library for performing inference using trained models.",
            "version": "0.2.0",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 16177160,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "8b56978e8c643580578d4041e8bef8e0",
                    "sha256": "0b799f681e0f4eac8d4a72ebc988dd2ca3ca52500431f5ede258dd27dfa5dfe8"
                },
                "downloads": -1,
                "filename": "unstructured_inference-0.2.0.tar.gz",
                "has_sig": false,
                "md5_digest": "8b56978e8c643580578d4041e8bef8e0",
                "packagetype": "sdist",
                "python_version": "source",
                "requires_python": ">=3.7.0",
                "size": 9265,
                "upload_time": "2022-12-21T20:38:39",
                "upload_time_iso_8601": "2022-12-21T20:38:39.871404Z",
                "url": "https://files.pythonhosted.org/packages/5b/d6/62ca7ad6d96d2d26be554dae52fc90616724b9a715da0848ded680aaca8f/unstructured_inference-0.2.0.tar.gz",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    }
}
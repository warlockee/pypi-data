{
    "0.0.1": {
        "info": {
            "author": "XuMing",
            "author_email": "xuming624@qq.com",
            "bugtrack_url": null,
            "classifiers": [
                "Intended Audience :: Science/Research",
                "License :: OSI Approved :: Apache Software License",
                "Operating System :: OS Independent",
                "Programming Language :: Python",
                "Programming Language :: Python :: 2.7",
                "Programming Language :: Python :: 3",
                "Topic :: Scientific/Engineering :: Artificial Intelligence",
                "Topic :: Text Processing :: Linguistic"
            ],
            "description": "[![PyPI version](https://badge.fury.io/py/pinyin-tokenizer.svg)](https://badge.fury.io/py/pinyin-tokenizer)\n[![Downloads](https://pepy.tech/badge/pinyin-tokenizer)](https://pepy.tech/project/pinyin-tokenizer)\n[![Contributions welcome](https://img.shields.io/badge/contributions-welcome-brightgreen.svg)](CONTRIBUTING.md)\n[![GitHub contributors](https://img.shields.io/github/contributors/shibing624/pinyin-tokenizer.svg)](https://github.com/shibing624/pinyin-tokenizer/graphs/contributors)\n[![License Apache 2.0](https://img.shields.io/badge/license-Apache%202.0-blue.svg)](LICENSE)\n[![python_vesion](https://img.shields.io/badge/Python-3.5%2B-green.svg)](requirements.txt)\n[![GitHub issues](https://img.shields.io/github/issues/shibing624/pinyin-tokenizer.svg)](https://github.com/shibing624/pinyin-tokenizer/issues)\n[![Wechat Group](http://vlog.sfyc.ltd/wechat_everyday/wxgroup_logo.png?imageView2/0/w/60/h/20)](#Contact)\n\n# Pinyin Tokenizer\npinyin tokenizer\uff08\u62fc\u97f3\u5206\u8bcd\u5668\uff09\uff0c\u5c06\u8fde\u7eed\u7684\u62fc\u97f3\u5207\u5206\u4e3a\u5355\u5b57\u62fc\u97f3\u5217\u8868\uff0c\u5f00\u7bb1\u5373\u7528\u3002python3\u5f00\u53d1\u3002\n\n\n**Guide**\n\n- [Feature](#Feature)\n- [Install](#install)\n- [Usage](#usage)\n- [Dataset](#Dataset)\n- [Contact](#Contact)\n- [Citation](#Citation)\n- [Reference](#reference)\n\n# Feature\n\n- \u57fa\u4e8e\u524d\u7f00\u6811\uff08PyTrie\uff09\u9ad8\u6548\u5feb\u901f\u628a\u8fde\u7eed\u62fc\u97f3\u5207\u5206\u4e3a\u5355\u5b57\u62fc\u97f3\u5217\u8868\uff0c\u4fbf\u4e8e\u540e\u7eed\u62fc\u97f3\u8f6c\u6c49\u5b57\u7b49\u5904\u7406\u3002\n\n# Install\n\n- Requirements and Installation\n\n```\npip install pinyintokenizer\n```\n\nor\n\n```\ngit clone https://github.com/shibing624/pinyin-tokenizer.git\ncd pinyin-tokenizer\npython setup.py install\n```\n\n\n# Usage\n\n## Pinyin Tokenizer\n\nexample\uff1a[examples/pinyin_tokenize_demo.py](examples/pinyin_tokenize_demo.py):\n\n\n```python\nimport sys\n\nsys.path.append('..')\nfrom pinyintokenizer import PinyinTokenizer\n\nif __name__ == '__main__':\n    m = PinyinTokenizer()\n    print(f\"{m.tokenize('wo3')}\")\n    print(f\"{m.tokenize('nihao')}\")\n    print(f\"{m.tokenize('liudehua')}\")\n    print(f\"{m.tokenize('liu de hua')}\")\n    print(f\"{m.tokenize('good luck')}\")\n    print(f\"{m.tokenize('xi anjiaotongdaxue')}\")\n```\n\noutput:\n\n```shell\n(['wo'], ['3'])\n(['ni', 'hao'], [])\n(['liu', 'de', 'hua'], [])\n(['liu', 'de', 'hua'], [' ', ' '])\n(['o', 'o', 'lu'], ['g', 'd', ' ', 'c', 'k'])\n(['xi', 'an', 'jiao', 'tong', 'da', 'xue'], [' '])\n```\n\n\n# Contact\n\n- Issue(\u5efa\u8bae)\uff1a[![GitHub issues](https://img.shields.io/github/issues/shibing624/pinyin-tokenizer.svg)](https://github.com/shibing624/pinyin-tokenizer/issues)\n- \u90ae\u4ef6\u6211\uff1axuming: xuming624@qq.com\n- \u5fae\u4fe1\u6211\uff1a\u52a0\u6211*\u5fae\u4fe1\u53f7\uff1axuming624*, \u8fdbPython-NLP\u4ea4\u6d41\u7fa4\uff0c\u5907\u6ce8\uff1a*\u59d3\u540d-\u516c\u53f8\u540d-NLP*\n<img src=\"docs/wechat.jpeg\" width=\"200\" />\n\n\n# Citation\n\n\u5982\u679c\u4f60\u5728\u7814\u7a76\u4e2d\u4f7f\u7528\u4e86pinyin-tokenizer\uff0c\u8bf7\u6309\u5982\u4e0b\u683c\u5f0f\u5f15\u7528\uff1a\n\nAPA:\n```latex\nXu, M. pinyin-tokenizer: Chinese Pinyin tokenizer toolkit for NLP (Version 0.0.1) [Computer software]. https://github.com/shibing624/pinyin-tokenizer\n```\n\nBibTeX:\n```latex\n@misc{pinyin-tokenizer,\n  title={pinyin-tokenizer: Chinese Pinyin tokenizer toolkit for NLP},\n  author={Xu Ming},\n  year={2022},\n  howpublished={\\url{https://github.com/shibing624/pinyin-tokenizer}},\n}\n```\n\n\n# License\n\n\n\u6388\u6743\u534f\u8bae\u4e3a [The Apache License 2.0](LICENSE)\uff0c\u53ef\u514d\u8d39\u7528\u505a\u5546\u4e1a\u7528\u9014\u3002\u8bf7\u5728\u4ea7\u54c1\u8bf4\u660e\u4e2d\u9644\u52a0**pinyin-tokenizer**\u7684\u94fe\u63a5\u548c\u6388\u6743\u534f\u8bae\u3002\n\n\n# Contribute\n\u9879\u76ee\u4ee3\u7801\u8fd8\u5f88\u7c97\u7cd9\uff0c\u5982\u679c\u5927\u5bb6\u5bf9\u4ee3\u7801\u6709\u6240\u6539\u8fdb\uff0c\u6b22\u8fce\u63d0\u4ea4\u56de\u672c\u9879\u76ee\uff0c\u5728\u63d0\u4ea4\u4e4b\u524d\uff0c\u6ce8\u610f\u4ee5\u4e0b\u4e24\u70b9\uff1a\n\n - \u5728`tests`\u6dfb\u52a0\u76f8\u5e94\u7684\u5355\u5143\u6d4b\u8bd5\n - \u4f7f\u7528`python -m pytest`\u6765\u8fd0\u884c\u6240\u6709\u5355\u5143\u6d4b\u8bd5\uff0c\u786e\u4fdd\u6240\u6709\u5355\u6d4b\u90fd\u662f\u901a\u8fc7\u7684\n\n\u4e4b\u540e\u5373\u53ef\u63d0\u4ea4PR\u3002\n\n\n# Related Projects\n\n- \u6c49\u5b57\u8f6c\u62fc\u97f3\uff1a[pypinyin](https://github.com/mozillazg/python-pinyin)\n- \u62fc\u97f3\u8f6c\u6c49\u5b57\uff1a[Pinyin2Hanzi](https://github.com/letiantian/Pinyin2Hanzi)",
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/shibing624/pinyin-tokenizer",
            "keywords": "pinyin-tokenizer,pinyin,pinyintokenizer,tokenizer",
            "license": "Apache 2.0",
            "maintainer": "",
            "maintainer_email": "",
            "name": "pinyintokenizer",
            "package_url": "https://pypi.org/project/pinyintokenizer/",
            "platform": null,
            "project_url": "https://pypi.org/project/pinyintokenizer/",
            "project_urls": {
                "Homepage": "https://github.com/shibing624/pinyin-tokenizer"
            },
            "release_url": "https://pypi.org/project/pinyintokenizer/0.0.1/",
            "requires_dist": null,
            "requires_python": "",
            "summary": "Pinyin Tokenizer, chinese pinyin tokenizer",
            "version": "0.0.1",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 16214566,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "6b50408f094379359b294e6ede5ea78f",
                    "sha256": "840c9824ca8b5eea0c07e50920608333e57105cee97d04e33cb677426107f6e7"
                },
                "downloads": -1,
                "filename": "pinyintokenizer-0.0.1.tar.gz",
                "has_sig": false,
                "md5_digest": "6b50408f094379359b294e6ede5ea78f",
                "packagetype": "sdist",
                "python_version": "source",
                "requires_python": null,
                "size": 9862,
                "upload_time": "2022-12-26T09:52:27",
                "upload_time_iso_8601": "2022-12-26T09:52:27.559098Z",
                "url": "https://files.pythonhosted.org/packages/1f/33/d7b2c14c7a873c71fdb9584cee575c4b1ba8d69c49fef167ec1cf4352938/pinyintokenizer-0.0.1.tar.gz",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    }
}
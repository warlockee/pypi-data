{
    "1.0": {
        "info": {
            "author": "Forrest Bajbek",
            "author_email": "forrestbajbek@gmail.com",
            "bugtrack_url": null,
            "classifiers": [
                "Development Status :: 5 - Production/Stable",
                "License :: OSI Approved :: Apache Software License",
                "Operating System :: MacOS :: MacOS X",
                "Operating System :: POSIX :: Linux",
                "Programming Language :: Python :: 3",
                "Programming Language :: Python :: 3.10",
                "Programming Language :: Python :: 3.11",
                "Programming Language :: Python :: 3.8",
                "Programming Language :: Python :: 3.9"
            ],
            "description": "# pyspark-regression\nA tool for regression testing Spark Dataframes in Python.\n\n## Installation\n### Via pip\nYou can install via pip: `pip install pyspark-regression==1.0`\n**Note:** This requires a working intallation of Spark 3+ and `pyspark>=3`.\n\n### Via Git\nTo install via git:\n```bash\ngit clone https://github.com/forrest-bajbek/pyspark-regression.git\ncd pyspark-regression\npip install .\n```\n**Note:** This requires a working intallation of Spark 3+ and `pyspark>=3`.\n\n### Via Docker\nTo build and then test the Docker Image:\n```bash\ngit clone https://github.com/forrest-bajbek/pyspark-regression.git\ncd pyspark-regression\nmake test\n```\n\nImages in Docker Hub coming soon.\n\n## What is a Regression Test?\nA [Regression Test](https://en.wikipedia.org/wiki/Regression_testing) ensures that changes to code only produce expected outcomes, introducing no _new_ bugs. These tests are particularly challenging when working with database tables, as the result can be too large to visually inspect. When updating a SQL transformation, Data Engineers must ensure that no rows or columns were unintentionally altered, even if the table has 300 columns and 400 billion rows.\n\n`pyspark-regression` reduces the complexity of Regression Testing for structured database tables. It standardizes the concepts and jargon associated with this topic, and implements a clean Python API for running regression tests against DataFrames in [Apache Spark](https://spark.apache.org/).\n\n## Example\nConsider the following table:\n| id | name | price |\n| - | - | - |\n| 1 | Taco | 3.001 |\n| 2 | Burrito | 6.50 |\n| 3 | flauta | 7.50 |\n\nImagine you are a Data Engineer, and you want to change the underlying ETL so that:\n1. The price for Tacos is rounded to 2 decimal places.\n1. The name for Flautas is capitalized.\n\nYou make your changes, and the new table looks like this:\n| id | name | price |\n| - | - | - |\n| 1 | Taco | **3.00** |\n| 2 | Burrito | 6.50 |\n| 3 | **Flauta** | 7.50 |\n\nRunning a regression test will help you confirm that the new ETL changed the data how you expected.\n\nLet's create the old and new tables as dataframes so we can run a Regression Test:\n```python\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql.types import *\nfrom pyspark_regression.regression import RegressionTest\n\nspark = SparkSession.builder.getOrCreate()\nspark.conf.set(\"spark.sql.shuffle.partitions\", 1)\n\nschema = StructType(\n    [\n        StructField(\"id\", IntegerType()),\n        StructField(\"name\", StringType()),\n        StructField(\"price\", DoubleType()),\n    ]\n)\n\n# The old data\ndf_old = spark.createDataFrame(\n    [\n        (1, 'Taco', 3.001),\n        (2, 'Burrito', 6.50),\n        (3, 'flauta', 7.50),\n    ],\n    schema=schema\n)\n\n# The new data\ndf_new = spark.createDataFrame(\n    [\n        (1, 'Taco', 3.00),  # Corrected price\n        (2, 'Burrito', 6.50),\n        (3, 'Flauta', 7.50),  # Corrected name\n    ],\n    schema=schema\n)\n\nregression_test = RegressionTest(\n    df_old=df_old,\n    df_new=df_new,\n    pk='id',\n)\n```\n\n\n`RegressionTest()` returns a Python dataclass with lots of methods that help you inspect how the two dataframes are different. Most notably, the `summary` method prints a comprehensive analysis in Markdown. Here's what happens when you run `print(regression_test.summary)`:\n```\n# Regression Test: df\n- run_id: de9bd4eb-5313-4057-badc-7322ee23b83b\n- run_time: 2022-05-25 08:53:50.581283\n\n## Result: **FAILURE**.\nPrinting Regression Report...\n\n### Table stats\n- Count records in old df: 3\n- Count records in new df: 3\n- Count pks in old df: 3\n- Count pks in new df: 3\n\n### Diffs\n- Columns with diffs: {'name', 'price'}\n- Number of records with diffs: 2 (%oT: 66.7%)\n\n Diff Summary:\n| column_name   | data_type   | diff_category        |   count_record | count_record_%oT   |\n|:--------------|:------------|:---------------------|---------------:|:-------------------|\n| name          | string      | capitalization added |              1 | 33.3%              |\n| price         | double      | rounding             |              1 | 33.3%              |\n\n Diff Samples: (5 samples per column_name, per diff_category, per is_duplicate)\n| column_name   | data_type   |   pk | old_value   | new_value   | diff_category        |\n|:--------------|:------------|-----:|:------------|:------------|:---------------------|\n| name          | string      |    3 | 'flauta'    | 'Flauta'    | capitalization added |\n| price         | double      |    1 | 3.001       | 3.0         | rounding             |\n```\n\nThe `RegressionTest` class provides low level access to all the methods used to build the summary:\n```python\n>>> print(rt.count_record_old) # count of records in df_old\n3\n\n>>> print(rt.count_record_new) # count of records in df_new\n3\n\n>>> print(rt.columns_diff) # Columns with diffs\n{'name', 'price'}\n\n>>> rt.df_diff.filter(\"column_name = 'price'\").show() # Show all diffs for 'price' column\n+-----------+---------+---+---------+---------+-------------+\n|column_name|data_type| pk|old_value|new_value|diff_category|\n+-----------+---------+---+---------+---------+-------------+\n|      price|   double|  1|    3.001|      3.0|     rounding|\n+-----------+---------+---+---------+---------+-------------+\n```\n\nThis example is accessable from the module:\n```python\nfrom pyspark_regression.example import regression_test\nprint(regression_test.summary)\n```\n\nFor more information on these methods, please see the docs (coming soon).\n",
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/forrest-bajbek/pyspark-regression",
            "keywords": "",
            "license": "",
            "maintainer": "",
            "maintainer_email": "",
            "name": "pyspark-regression",
            "package_url": "https://pypi.org/project/pyspark-regression/",
            "platform": null,
            "project_url": "https://pypi.org/project/pyspark-regression/",
            "project_urls": {
                "Homepage": "https://github.com/forrest-bajbek/pyspark-regression"
            },
            "release_url": "https://pypi.org/project/pyspark-regression/1.0/",
            "requires_dist": [
                "black ; extra == 'dev'",
                "build ; extra == 'dev'",
                "flake8 ; extra == 'dev'",
                "isort ; extra == 'dev'",
                "pytest ; extra == 'dev'",
                "wheel ; extra == 'dev'"
            ],
            "requires_python": ">=3.8",
            "summary": "A tool for regression testing Spark Dataframes in Python",
            "version": "1.0",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 16274100,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "9e98ccce71f1486f2d99dbec62c27c99",
                    "sha256": "7220f31aaeb68356112d8ff6e5418739b3c298c8123c116b2eb10fb75e9e6f7e"
                },
                "downloads": -1,
                "filename": "pyspark_regression-1.0-py3-none-any.whl",
                "has_sig": false,
                "md5_digest": "9e98ccce71f1486f2d99dbec62c27c99",
                "packagetype": "bdist_wheel",
                "python_version": "py3",
                "requires_python": ">=3.8",
                "size": 14064,
                "upload_time": "2023-01-01T20:14:05",
                "upload_time_iso_8601": "2023-01-01T20:14:05.203814Z",
                "url": "https://files.pythonhosted.org/packages/c5/5e/c15a6330d070e476d2eba4d773b9855ed2e3b146fd0ec955b37fbe7f1cbe/pyspark_regression-1.0-py3-none-any.whl",
                "yanked": false,
                "yanked_reason": null
            },
            {
                "comment_text": "",
                "digests": {
                    "md5": "d5e4114b8fbabbe14cee3e9d1a75020f",
                    "sha256": "2e52c0f8381bf3b480a970fa41bfc71b234d51612905cbc29cc7f0617db6029e"
                },
                "downloads": -1,
                "filename": "pyspark-regression-1.0.tar.gz",
                "has_sig": false,
                "md5_digest": "d5e4114b8fbabbe14cee3e9d1a75020f",
                "packagetype": "sdist",
                "python_version": "source",
                "requires_python": ">=3.8",
                "size": 15469,
                "upload_time": "2023-01-01T20:14:07",
                "upload_time_iso_8601": "2023-01-01T20:14:07.092684Z",
                "url": "https://files.pythonhosted.org/packages/59/35/3ae27a1ae794f754fd8cddb23b27da2a0b35d7c058860425e37b281c2748/pyspark-regression-1.0.tar.gz",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    }
}
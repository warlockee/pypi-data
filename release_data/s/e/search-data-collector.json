{
    "0.2.0": {
        "info": {
            "author": "Simon Blanke",
            "author_email": "simon.blanke@yahoo.com",
            "bugtrack_url": null,
            "classifiers": [
                "Intended Audience :: Developers",
                "Intended Audience :: Information Technology",
                "Intended Audience :: Science/Research",
                "License :: OSI Approved :: MIT License",
                "Operating System :: OS Independent",
                "Programming Language :: Python :: 3",
                "Programming Language :: Python :: 3.5",
                "Programming Language :: Python :: 3.6",
                "Programming Language :: Python :: 3.7",
                "Topic :: Scientific/Engineering :: Information Analysis",
                "Topic :: Scientific/Engineering :: Mathematics",
                "Topic :: Software Development :: Libraries :: Python Modules"
            ],
            "description": "<H1 align=\"center\">\n    Search Data Collector\n</H1>\n\n\n<p align=\"center\">\n  <a href=\"https://github.com/SimonBlanke/search-data-collector/actions\">\n    <img src=\"https://github.com/SimonBlanke/search-data-collector/actions/workflows/tests.yml/badge.svg?branch=main\" alt=\"img not loaded: try F5 :)\">\n  </a>\n  <a href=\"https://app.codecov.io/gh/SimonBlanke/search-data-collector\">\n    <img src=\"https://img.shields.io/codecov/c/github/SimonBlanke/search-data-collector/main&logo=codecov\" alt=\"img not loaded: try F5 :)\">\n  </a>\n</p>\n\n\n<H2 align=\"center\">\n    Thread-safe and atomic collection of tabular data into csv-files.\n</H2>\n\n<br>\n\nThe search-data-collector provides a single class with with following methods:\n - save\n - append\n - load\n - remove\n\nIt was created as a utility function for the [Hyperactive-package](https://github.com/SimonBlanke/Hyperactive). It was intended to be used as a search-data collection tool. The search-data can be collected during the optimization run as a dictionary via `append` or after the run as a dataframe with the `save`-method. <br>\nThe `append`-method is thread-safe to work with hyperactive-multiprocessing. The `save`-method is atomic to avoid accidental data-loss. <br>\nThe search-data-collector handles functions in the data by converting them to strings. If the data is loaded you can pass the search_space to convert the strings back to functions.\n\n\n<br>\n\n## Installation\n\n```console\npip install search-data-collector \n```\n\n\n<br>\n\n## Example\n\n```python\nimport numpy as np\nfrom hyperactive import Hyperactive\nfrom search_data_collector import DataCollector\n\ncollector = DataCollector(\"./search_data.csv\") # the csv is created automatically\n\n\ndef ackley_function(para):\n    x, y = para[\"x\"], para[\"y\"]\n\n    loss = (\n        -20 * np.exp(-0.2 * np.sqrt(0.5 * (x * x + y * y)))\n        - np.exp(0.5 * (np.cos(2 * np.pi * x) + np.cos(2 * np.pi * y)))\n        + np.exp(1)\n        + 20\n    )\n\n    data_dict = para.para_dict\n    data_dict[\"score\"] = -loss\n    collector.append(data_dict)  # you can append a dictionary to the csv\n\n    return -loss\n\n\nsearch_space = {\n    \"x\": list(np.arange(-10, 10, 0.01)),\n    \"y\": list(np.arange(-10, 10, 0.01)),\n}\n\n\nhyper = Hyperactive()\nhyper.add_search(ackley_function, search_space, n_iter=3000)\nhyper.run()\nsearch_data = hyper.search_data(ackley_function)\n\n# collector.save(search_data) # save a dataframe instead of appending a dictionary\n\nsearch_data_l = collector.load(search_space)  # load data\n\nprint(search_data_l)\n```\n",
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/SimonBlanke/search-data-collector",
            "keywords": "data-science",
            "license": "MIT",
            "maintainer": "",
            "maintainer_email": "",
            "name": "search-data-collector",
            "package_url": "https://pypi.org/project/search-data-collector/",
            "platform": null,
            "project_url": "https://pypi.org/project/search-data-collector/",
            "project_urls": {
                "Homepage": "https://github.com/SimonBlanke/search-data-collector"
            },
            "release_url": "https://pypi.org/project/search-data-collector/0.2.0/",
            "requires_dist": [
                "numpy",
                "pandas",
                "filelock"
            ],
            "requires_python": ">=3.5",
            "summary": "Thread safe and atomic data collection into csv-files",
            "version": "0.2.0",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 16280316,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "ff2ad7de1c3e4144c6587f520c97a1eb",
                    "sha256": "f2b3a98432d92a8d566d864f1c8a5761255bcdda7826e4d14064c175551489a6"
                },
                "downloads": -1,
                "filename": "search_data_collector-0.2.0-py3-none-any.whl",
                "has_sig": false,
                "md5_digest": "ff2ad7de1c3e4144c6587f520c97a1eb",
                "packagetype": "bdist_wheel",
                "python_version": "py3",
                "requires_python": ">=3.5",
                "size": 12523,
                "upload_time": "2023-01-02T16:14:44",
                "upload_time_iso_8601": "2023-01-02T16:14:44.092730Z",
                "url": "https://files.pythonhosted.org/packages/83/13/c2630e4969e8176081c9b7be220f5684680f93b158b89d93e9d03bdf3fba/search_data_collector-0.2.0-py3-none-any.whl",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    }
}
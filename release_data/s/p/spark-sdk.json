{
    "0.3.26": {
        "info": {
            "author": "duyvnc",
            "author_email": "duyvnc@fpt.com.vn",
            "bugtrack_url": null,
            "classifiers": [
                "License :: OSI Approved :: MIT License",
                "Operating System :: OS Independent",
                "Programming Language :: Python :: 3"
            ],
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "http://git.bigdata.local/data-engineers/sdk/utilities/-/tree/duyvnc",
            "keywords": "",
            "license": "duyvnc",
            "maintainer": "",
            "maintainer_email": "",
            "name": "spark-sdk",
            "package_url": "https://pypi.org/project/spark-sdk/",
            "platform": null,
            "project_url": "https://pypi.org/project/spark-sdk/",
            "project_urls": {
                "Bug Tracker": "https://github.com/pypa/sampleproject/issues",
                "Homepage": "http://git.bigdata.local/data-engineers/sdk/utilities/-/tree/duyvnc"
            },
            "release_url": "https://pypi.org/project/spark-sdk/0.3.26/",
            "requires_dist": [
                "pyspark (>=3.0.0)",
                "pyarrow (>=8.0.0)",
                "pycryptodome",
                "pandas",
                "thrift",
                "hmsclient",
                "sqlglot",
                "findspark"
            ],
            "requires_python": ">=3.6",
            "summary": "Function to help Data Scientist work more effectively with DWH",
            "version": "0.3.26",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 15771726,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "65f7b5dbd049c8812d2d72fe09dd539c",
                    "sha256": "e6f1eec0b2624172b5eead6b877b70e99764db65dd186d926ddaac277965afa6"
                },
                "downloads": -1,
                "filename": "spark_sdk-0.3.26-py3-none-any.whl",
                "has_sig": false,
                "md5_digest": "65f7b5dbd049c8812d2d72fe09dd539c",
                "packagetype": "bdist_wheel",
                "python_version": "py3",
                "requires_python": ">=3.6",
                "size": 19475,
                "upload_time": "2022-07-19T07:59:00",
                "upload_time_iso_8601": "2022-07-19T07:59:00.179289Z",
                "url": "https://files.pythonhosted.org/packages/3d/b5/827ca106f825888de0277c75c98e37eba0cd12eb0dd6d157c0b36fc0870b/spark_sdk-0.3.26-py3-none-any.whl",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "0.3.27": {
        "info": {
            "author": "duyvnc",
            "author_email": "duyvnc@fpt.com.vn",
            "bugtrack_url": null,
            "classifiers": [
                "License :: OSI Approved :: MIT License",
                "Operating System :: OS Independent",
                "Programming Language :: Python :: 3"
            ],
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "http://git.bigdata.local/data-engineers/sdk/utilities/-/tree/duyvnc",
            "keywords": "",
            "license": "duyvnc",
            "maintainer": "",
            "maintainer_email": "",
            "name": "spark-sdk",
            "package_url": "https://pypi.org/project/spark-sdk/",
            "platform": null,
            "project_url": "https://pypi.org/project/spark-sdk/",
            "project_urls": {
                "Bug Tracker": "https://github.com/pypa/sampleproject/issues",
                "Homepage": "http://git.bigdata.local/data-engineers/sdk/utilities/-/tree/duyvnc"
            },
            "release_url": "https://pypi.org/project/spark-sdk/0.3.27/",
            "requires_dist": [
                "pyspark (>=3.0.0)",
                "pyarrow (>=8.0.0)",
                "pycryptodome",
                "pandas",
                "thrift",
                "hmsclient",
                "sqlglot",
                "findspark"
            ],
            "requires_python": ">=3.6",
            "summary": "Function to help Data Scientist work more effectively with DWH",
            "version": "0.3.27",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 15771726,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "3c5a826a8c814bbb72875a23ca5914fd",
                    "sha256": "340ee330356749963754ce0885d2cb06320463b1c952a3dccbb15afd1bf66f85"
                },
                "downloads": -1,
                "filename": "spark_sdk-0.3.27-py3-none-any.whl",
                "has_sig": false,
                "md5_digest": "3c5a826a8c814bbb72875a23ca5914fd",
                "packagetype": "bdist_wheel",
                "python_version": "py3",
                "requires_python": ">=3.6",
                "size": 19494,
                "upload_time": "2022-07-19T08:38:28",
                "upload_time_iso_8601": "2022-07-19T08:38:28.526991Z",
                "url": "https://files.pythonhosted.org/packages/84/9c/d0f001bc748ecdee159c634c928039fd031057f59ad701e0190b29c0e496/spark_sdk-0.3.27-py3-none-any.whl",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "0.3.28": {
        "info": {
            "author": "duyvnc",
            "author_email": "duyvnc@fpt.com.vn",
            "bugtrack_url": null,
            "classifiers": [
                "License :: OSI Approved :: MIT License",
                "Operating System :: OS Independent",
                "Programming Language :: Python :: 3"
            ],
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "http://git.bigdata.local/data-engineers/sdk/utilities/-/tree/duyvnc",
            "keywords": "",
            "license": "duyvnc",
            "maintainer": "",
            "maintainer_email": "",
            "name": "spark-sdk",
            "package_url": "https://pypi.org/project/spark-sdk/",
            "platform": null,
            "project_url": "https://pypi.org/project/spark-sdk/",
            "project_urls": {
                "Bug Tracker": "https://github.com/pypa/sampleproject/issues",
                "Homepage": "http://git.bigdata.local/data-engineers/sdk/utilities/-/tree/duyvnc"
            },
            "release_url": "https://pypi.org/project/spark-sdk/0.3.28/",
            "requires_dist": [
                "pyspark (>=3.0.0)",
                "pyarrow (>=8.0.0)",
                "pycryptodome",
                "pandas",
                "thrift",
                "hmsclient",
                "sqlglot",
                "findspark"
            ],
            "requires_python": ">=3.6",
            "summary": "Function to help Data Scientist work more effectively with DWH",
            "version": "0.3.28",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 15771726,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "ae99f66de5bde5e315d90e97476fd404",
                    "sha256": "3676ee57bf34d51d0ad879dd1725adc442dc1102fc869c845eda9c7a96f5d53f"
                },
                "downloads": -1,
                "filename": "spark_sdk-0.3.28-py3-none-any.whl",
                "has_sig": false,
                "md5_digest": "ae99f66de5bde5e315d90e97476fd404",
                "packagetype": "bdist_wheel",
                "python_version": "py3",
                "requires_python": ">=3.6",
                "size": 19491,
                "upload_time": "2022-07-22T06:52:13",
                "upload_time_iso_8601": "2022-07-22T06:52:13.733253Z",
                "url": "https://files.pythonhosted.org/packages/be/5a/2e0f356d7ff206a1f91e57d9e828a5124bddc2592ef8a459086b9292c732/spark_sdk-0.3.28-py3-none-any.whl",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "0.3.29": {
        "info": {
            "author": "duyvnc",
            "author_email": "duyvnc@fpt.com.vn",
            "bugtrack_url": null,
            "classifiers": [
                "License :: OSI Approved :: MIT License",
                "Operating System :: OS Independent",
                "Programming Language :: Python :: 3"
            ],
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "http://git.bigdata.local/data-engineers/sdk/utilities/-/tree/duyvnc",
            "keywords": "",
            "license": "duyvnc",
            "maintainer": "",
            "maintainer_email": "",
            "name": "spark-sdk",
            "package_url": "https://pypi.org/project/spark-sdk/",
            "platform": null,
            "project_url": "https://pypi.org/project/spark-sdk/",
            "project_urls": {
                "Bug Tracker": "https://github.com/pypa/sampleproject/issues",
                "Homepage": "http://git.bigdata.local/data-engineers/sdk/utilities/-/tree/duyvnc"
            },
            "release_url": "https://pypi.org/project/spark-sdk/0.3.29/",
            "requires_dist": [
                "pyspark (>=3.0.0)",
                "pyarrow (>=8.0.0)",
                "pycryptodome",
                "pandas",
                "thrift",
                "hmsclient",
                "sqlglot",
                "findspark"
            ],
            "requires_python": ">=3.6",
            "summary": "Function to help Data Scientist work more effectively with DWH",
            "version": "0.3.29",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 15771726,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "a9ed8fcb251bb137ff22e3c70a5ba288",
                    "sha256": "ee7fa9b0f15378871c0b8335e0224226ef64cce49837a139cb95fe348adb760b"
                },
                "downloads": -1,
                "filename": "spark_sdk-0.3.29-py3-none-any.whl",
                "has_sig": false,
                "md5_digest": "a9ed8fcb251bb137ff22e3c70a5ba288",
                "packagetype": "bdist_wheel",
                "python_version": "py3",
                "requires_python": ">=3.6",
                "size": 19863,
                "upload_time": "2022-08-05T06:50:54",
                "upload_time_iso_8601": "2022-08-05T06:50:54.678597Z",
                "url": "https://files.pythonhosted.org/packages/63/d3/288b6a8c61af93b2b43c777d0c879b24d5ea080db1e89dc04d69625a5080/spark_sdk-0.3.29-py3-none-any.whl",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "0.3.35": {
        "info": {
            "author": "duyvnc",
            "author_email": "duyvnc@fpt.com.vn",
            "bugtrack_url": null,
            "classifiers": [
                "License :: OSI Approved :: MIT License",
                "Operating System :: OS Independent",
                "Programming Language :: Python :: 3"
            ],
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "http://git.bigdata.local/data-engineers/sdk/utilities/-/tree/duyvnc",
            "keywords": "",
            "license": "duyvnc",
            "maintainer": "",
            "maintainer_email": "",
            "name": "spark-sdk",
            "package_url": "https://pypi.org/project/spark-sdk/",
            "platform": null,
            "project_url": "https://pypi.org/project/spark-sdk/",
            "project_urls": {
                "Bug Tracker": "https://github.com/pypa/sampleproject/issues",
                "Homepage": "http://git.bigdata.local/data-engineers/sdk/utilities/-/tree/duyvnc"
            },
            "release_url": "https://pypi.org/project/spark-sdk/0.3.35/",
            "requires_dist": [
                "pyspark (>=3.0.0)",
                "pyarrow (>=8.0.0)",
                "pycryptodome",
                "pandas",
                "thrift",
                "hmsclient",
                "sqlglot",
                "findspark"
            ],
            "requires_python": ">=3.6",
            "summary": "Function to help Data Scientist work more effectively with DWH",
            "version": "0.3.35",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 15771726,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "4e26556b35f2ef725d238e8048e540ba",
                    "sha256": "f45836d0b0f6a8c8484d6ca66167c7212a31939dac6559e279548cfd80f06f67"
                },
                "downloads": -1,
                "filename": "spark_sdk-0.3.35-py3-none-any.whl",
                "has_sig": false,
                "md5_digest": "4e26556b35f2ef725d238e8048e540ba",
                "packagetype": "bdist_wheel",
                "python_version": "py3",
                "requires_python": ">=3.6",
                "size": 20117,
                "upload_time": "2022-08-18T16:03:57",
                "upload_time_iso_8601": "2022-08-18T16:03:57.371651Z",
                "url": "https://files.pythonhosted.org/packages/e7/ce/3ea49c788ca485a007782c49a8c0a0f4967617329760390d4cdd4aa3eda4/spark_sdk-0.3.35-py3-none-any.whl",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "0.3.38": {
        "info": {
            "author": "duyvnc",
            "author_email": "duyvnc@fpt.com.vn",
            "bugtrack_url": null,
            "classifiers": [
                "License :: OSI Approved :: MIT License",
                "Operating System :: OS Independent",
                "Programming Language :: Python :: 3"
            ],
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "http://git.bigdata.local/data-engineers/sdk/utilities/-/tree/duyvnc",
            "keywords": "",
            "license": "duyvnc",
            "maintainer": "",
            "maintainer_email": "",
            "name": "spark-sdk",
            "package_url": "https://pypi.org/project/spark-sdk/",
            "platform": null,
            "project_url": "https://pypi.org/project/spark-sdk/",
            "project_urls": {
                "Bug Tracker": "https://github.com/pypa/sampleproject/issues",
                "Homepage": "http://git.bigdata.local/data-engineers/sdk/utilities/-/tree/duyvnc"
            },
            "release_url": "https://pypi.org/project/spark-sdk/0.3.38/",
            "requires_dist": [
                "pyspark (>=3.0.0)",
                "pyarrow (>=8.0.0)",
                "pycryptodome",
                "pandas",
                "thrift",
                "hmsclient",
                "sqlglot",
                "findspark"
            ],
            "requires_python": ">=3.6",
            "summary": "Function to help Data Scientist work more effectively with DWH",
            "version": "0.3.38",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 15771726,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "59f6b911a36708a7bff3aba160b54a3b",
                    "sha256": "c2fcacaa77c84958eb8bb59ef95528c77903d161517e2c9b86051fe2d4d471ff"
                },
                "downloads": -1,
                "filename": "spark_sdk-0.3.38-py3-none-any.whl",
                "has_sig": false,
                "md5_digest": "59f6b911a36708a7bff3aba160b54a3b",
                "packagetype": "bdist_wheel",
                "python_version": "py3",
                "requires_python": ">=3.6",
                "size": 20438,
                "upload_time": "2022-09-27T01:47:36",
                "upload_time_iso_8601": "2022-09-27T01:47:36.294021Z",
                "url": "https://files.pythonhosted.org/packages/04/14/3bf2ffdd42c127c549cbea5dfa71de25fd4a671736e9a4104edf0da25739/spark_sdk-0.3.38-py3-none-any.whl",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "0.4.10": {
        "info": {
            "author": "duyvnc",
            "author_email": "duyvnc@fpt.com.vn",
            "bugtrack_url": null,
            "classifiers": [
                "License :: OSI Approved :: MIT License",
                "Operating System :: OS Independent",
                "Programming Language :: Python :: 3"
            ],
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "http://git.bigdata.local/data-engineers/sdk/utilities",
            "keywords": "",
            "license": "duyvnc",
            "maintainer": "",
            "maintainer_email": "",
            "name": "spark-sdk",
            "package_url": "https://pypi.org/project/spark-sdk/",
            "platform": null,
            "project_url": "https://pypi.org/project/spark-sdk/",
            "project_urls": {
                "Bug Tracker": "https://github.com/pypa/sampleproject/issues",
                "Homepage": "http://git.bigdata.local/data-engineers/sdk/utilities"
            },
            "release_url": "https://pypi.org/project/spark-sdk/0.4.10/",
            "requires_dist": [
                "pyspark (>=3.0.2)",
                "pyarrow (>=8.0.0)",
                "pycryptodome",
                "pandas (>=1.0.5)",
                "thrift",
                "hmsclient",
                "sqlglot",
                "findspark"
            ],
            "requires_python": ">=3.6",
            "summary": "Function to help Data Scientist work more effectively with DWH",
            "version": "0.4.10",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 15771726,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "9411c42660b20a1692f41492e7fb812b",
                    "sha256": "ce6a3258fffa2f4a3e141759d6dbde1b5a77282791bd2f946d40b779623c8914"
                },
                "downloads": -1,
                "filename": "spark_sdk-0.4.10-py3-none-any.whl",
                "has_sig": false,
                "md5_digest": "9411c42660b20a1692f41492e7fb812b",
                "packagetype": "bdist_wheel",
                "python_version": "py3",
                "requires_python": ">=3.6",
                "size": 32238,
                "upload_time": "2022-11-15T07:08:10",
                "upload_time_iso_8601": "2022-11-15T07:08:10.379754Z",
                "url": "https://files.pythonhosted.org/packages/1f/4b/0ede9db643a2f0f718b0bb078b57baf1b9ee7f17f67ae10dbe1b5cd8d013/spark_sdk-0.4.10-py3-none-any.whl",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "0.4.9": {
        "info": {
            "author": "duyvnc",
            "author_email": "duyvnc@fpt.com.vn",
            "bugtrack_url": null,
            "classifiers": [
                "License :: OSI Approved :: MIT License",
                "Operating System :: OS Independent",
                "Programming Language :: Python :: 3"
            ],
            "description": "# Install package\n```bash\npip install spark-sdk --upgrade\n```\n\n# Get Spark\n```python\nimport spark_sdk as ss\nspark = ss.PySpark(yarn=False, num_executors=4, executor_memory='4G').spark\n\n# Yarn mode\nspark = ss.PySpark(yarn=True, driver_memory='3G', num_executors=4, executor_memory='4G').spark\n\n# Add more spark config\nspark = ss.PySpark(yarn=False, driver_memory='8G', num_executors=4, executor_memory='4G',\n                  add_on_config1=(\"spark.sql.catalog.spark_catalog\",\"org.apache.spark.sql.delta.catalog.DeltaCatalog\"),\n                  add_on_config2=('spark.databricks.delta.retentionDurationCheck.enabled', 'false')\n                  ).spark\n```\n# Store data to dwh\n```python\n\n# step 1 read data\nELT_DATE = '2021-12-01'\nELT_STR = ELT_DATE[:7]\nimport pandas as pd\ndf1 = pd.read_csv('./data.csv', sep='\\t')\n\n\nimport spark_sdk as ss\n\n# function to store to dwh\ndf1.to_dwh(    \n    hdfs_path=\"path/to/data/test1.parquet/\", # path hdfs\n    partition_by=\"m\", # column time want to partition\n    partition_date=ELT_DATE, # partition date\n    database=\"database_name\", # database name\n    table_name=\"test1\", # table name\n    repartition=True\n)\n\n\n# function to read from dwh\n# method 1: using pandas\nimport spark_sdk as ss\nimport pandas as pd\n\npandas_df = pd.read_dwh('database.table_name', filters=\"\"\"m='2022-04-01'\"\"\")\n\n# method 2: sql\nsparkDF = ss.sql(\"\"\"\nSELECT *\nFROM database_name.table1\nWHERE m='2022-04-01'\n\"\"\")\n\ndf = sparkDF.toPandas()\n\n\n# method 3: read_table\nsparkDF = ss.read_table('database_name.table')\nsparkDF = sparkDF.filter(\"m == '2022-04-01'\")\n\ndf = sparkDF.toPandas()\n\n\n# IF got error timestamp out of range\nsparkDF = ss.limit_timestamp(sparkDF).toPandas()\n\n# IF YOU WANT TO DELETE DATA\n# Link hdfs_file to table\n# When to drop it also delete data\nss.drop_table_and_delete_data('database_name.test1')\n\n# IF JUST WANT TO DELETE TABLE NOT DELETE DATA\nss.drop_table('database_name.test1')\n\n```\n# Delta format\n# function to store to dwh\n```python\ndf1.to_dwh(\n    # just end path with delta then table will be store in delta format\n    hdfs_path=\"path/to/data/test1.delta/\", \n    partition_by=\"m\", # column time want to partition\n    partition_date=ELT_DATE, # partition date\n    database=\"database_name\", # database name\n    table_name=\"test1\",\n    repartition=True# table name\n)\n\n# read table not read file\nsparkDF = ss.sql(\"\"\"\nSELECT *\nFROM database_name.table1\nWHERE m='2022-04-01'\n\"\"\")\n\n```\n\n\n# Decrypt Data\n\n## method 1: sql\nUsing Spark SQL\n```python\nimport spark_sdk as ps\n\nkey = '1234' # contact Data Owner to get key\n\ndf = ps.sql(f\"\"\"\nselect fdecrypt(column_name, \"{key}\") column_name\nfrom database_name.table_name\nlimit 50000\n\"\"\").toPandas()\n```\n\n\n## method 2: using pandas\nUsing pandas\n```python\nimport spark_sdk as ss\ndf['new_column'] = df['column'].decrypt_column(key)\n\n# function will return dataframe with column_decrypted\n```\n\n# method 3\nUsing pandas apply function\n```python\nfrom spark_sdk import decrypt\ndf['decrypted'] = df['encrypted'].apply(decrypt,args=(\"YOUR_KEY\",))\n```\n\n# Encrypt data\n```python\nimport spark_sdk as ss\n\n\n# function to store to dwh\ndf.to_dwh(    \n    hdfs_path=\"path/to/data/test1.parquet/\", # path hdfs\n    partition_by=\"m\", # column time want to partition\n    partition_date=ELT_DATE, # partition date\n    database=\"database_name\", # database name\n    table_name=\"test1\", # table name\n    encrypt_columns=['column1','column2'], # list column name need to encrypt\n    keys_path = '/path/to/store/keys.json' # if you add encrypt_columns, you need to have keys_path to store keys\n)\n\nss.PySpark().stop()\n```\n\n# Create Yaml File Mapping data from CSV to DWH\n```python\nfrom spark_sdk import CreateYamlDWH\ncreate_yaml = CreateYamlDWH(\ncsv_file = 'data.csv',\nhdfs_path = '/path/to/data/table_name.parquet',\nsep = '\\t',\ndatabase_name = 'database_name',\ntable_name = 'table_name',\nyaml_path = '/path/to/yaml/file/'\n)\n\ncreate_yaml.generate_yaml_file()\n```\n\n# Store spark.sql.DataFrame\n```python\nfrom spark_sdk.src import spark_sdk as ss\nsparkDF = ss.sql(\"\"\"select * from database.table_name limit 1000\"\"\")\n\nELT_DATE = '2022-06-10'\nsparkDF.to_dwh(\n    hdfs_path=\"path/to/data/test6.parquet/\", # path hdfs\n    partition_by=\"m\", # column time want to partition\n    partition_date=ELT_DATE, # partition date\n    database=\"database_name\", # database name\n    table_name=\"test6\", # table name\n    repartition=True,\n    driver_memory='4G', executor_memory='4g', num_executors='1', port='4090', yarn=True\n)\n```\n\n# Working with hdfs\n```python\nmkdir, cat, exists, info, open\n\n# list file\nss.ls('/path/data')\n\n# create new path \nss.mkdir('/path/create/')\n\n# create new path \nss.exists('/check/path/exists') # return True if exists\n\n# print info\nss.info('/path/info/')\n\n# open file like normal file\nimport json\nwith ss.open('/path/to/file.json', mode='rb') as file:\n    data = json.load(file)\n\nimport json\nfrom spark_sdk import Utf8Encoder\ndata = {'user': 1, 'code': '456'}\nwith ss.open('/path/to/file.json', mode='wb') as file:\n    json.dump(data, Utf8Encoder(file), indent=4)\n\n\njson__file = ss.read_json('/path/to/file.json')\nss.write_json(data, '/path/to_file.json')\n\nsparkDF = ss.read_csv(\"file:///path/to/data.csv\", sep='\\t') # with local file\nsparkDF = ss.read_csv(\"/path/to/data.csv\", sep='\\t') # with hdfs file\n\n# mode in ['rb', 'wb', 'ab']\n```\n\n\n\n",
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "http://git.bigdata.local/data-engineers/sdk/utilities",
            "keywords": "",
            "license": "duyvnc",
            "maintainer": "",
            "maintainer_email": "",
            "name": "spark-sdk",
            "package_url": "https://pypi.org/project/spark-sdk/",
            "platform": null,
            "project_url": "https://pypi.org/project/spark-sdk/",
            "project_urls": {
                "Bug Tracker": "https://github.com/pypa/sampleproject/issues",
                "Homepage": "http://git.bigdata.local/data-engineers/sdk/utilities"
            },
            "release_url": "https://pypi.org/project/spark-sdk/0.4.9/",
            "requires_dist": [
                "pyspark (>=3.0.2)",
                "pyarrow (>=8.0.0)",
                "pycryptodome",
                "pandas (>=1.3.4)",
                "thrift",
                "hmsclient",
                "sqlglot",
                "findspark"
            ],
            "requires_python": ">=3.6",
            "summary": "Function to help Data Scientist work more effectively with DWH",
            "version": "0.4.9",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 15771726,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "11706122d665351b49ffbe5c7ef72758",
                    "sha256": "162531dcc53166395e655baaaa64beb5439b008d537513f809a073f2f6655f53"
                },
                "downloads": -1,
                "filename": "spark_sdk-0.4.9-py3-none-any.whl",
                "has_sig": false,
                "md5_digest": "11706122d665351b49ffbe5c7ef72758",
                "packagetype": "bdist_wheel",
                "python_version": "py3",
                "requires_python": ">=3.6",
                "size": 32225,
                "upload_time": "2022-11-01T06:43:26",
                "upload_time_iso_8601": "2022-11-01T06:43:26.386463Z",
                "url": "https://files.pythonhosted.org/packages/78/ef/a94fc9e735951687c8ae5c09971b47a197f864afe848bd3c4ada1591b88a/spark_sdk-0.4.9-py3-none-any.whl",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    }
}
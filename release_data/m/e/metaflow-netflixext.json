{
    "0.0.1": {
        "info": {
            "author": "Netflix Metaflow Developers",
            "author_email": "metaflow-dev@netflix.com",
            "bugtrack_url": null,
            "classifiers": [],
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "",
            "keywords": "",
            "license": "",
            "maintainer": "",
            "maintainer_email": "",
            "name": "metaflow-netflixext",
            "package_url": "https://pypi.org/project/metaflow-netflixext/",
            "platform": null,
            "project_url": "https://pypi.org/project/metaflow-netflixext/",
            "project_urls": null,
            "release_url": "https://pypi.org/project/metaflow-netflixext/0.0.1/",
            "requires_dist": [
                "metaflow (>=2.7.16)"
            ],
            "requires_python": ">3.5",
            "summary": "EXPERIMENTAL Metaflow extensions from Netflix",
            "version": "0.0.1",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 16178690,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "ebcb31a48391fc99ce57e34cd953859b",
                    "sha256": "8de67064915295ab9093098eb2ca78fa863b5d8ba0f81290bcdd6b6a5fda3a6b"
                },
                "downloads": -1,
                "filename": "metaflow_netflixext-0.0.1-py2.py3-none-any.whl",
                "has_sig": false,
                "md5_digest": "ebcb31a48391fc99ce57e34cd953859b",
                "packagetype": "bdist_wheel",
                "python_version": "py2.py3",
                "requires_python": ">3.5",
                "size": 83919,
                "upload_time": "2022-12-21T19:11:19",
                "upload_time_iso_8601": "2022-12-21T19:11:19.924401Z",
                "url": "https://files.pythonhosted.org/packages/b5/16/72f0d8f3836bf95ac0aa8426ff0273020cbcc0b8dadd2661268815d0b8e0/metaflow_netflixext-0.0.1-py2.py3-none-any.whl",
                "yanked": false,
                "yanked_reason": null
            },
            {
                "comment_text": "",
                "digests": {
                    "md5": "0587b868fc606f9d482d558959fdc7bf",
                    "sha256": "03b68a91e991183de3f3fd3467e550ff2d887308be0c05e2df6cd85a2822670c"
                },
                "downloads": -1,
                "filename": "metaflow-netflixext-0.0.1.tar.gz",
                "has_sig": false,
                "md5_digest": "0587b868fc606f9d482d558959fdc7bf",
                "packagetype": "sdist",
                "python_version": "source",
                "requires_python": ">3.5",
                "size": 81260,
                "upload_time": "2022-12-21T19:11:21",
                "upload_time_iso_8601": "2022-12-21T19:11:21.253964Z",
                "url": "https://files.pythonhosted.org/packages/4a/9b/0ce14e37f9be2a536890f542890fb07f4d8181068451105e85816fe26392/metaflow-netflixext-0.0.1.tar.gz",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "0.0.2": {
        "info": {
            "author": "Netflix Metaflow Developers",
            "author_email": "metaflow-dev@netflix.com",
            "bugtrack_url": null,
            "classifiers": [],
            "description": "# Metaflow Experimental Extensions from Netflix\nThis repository contains *non-supported* extensions for Metaflow.\n- If you are within Netflix and are looking for the Netflix version of Metaflow,\n  this is *not* it.\n- If you are looking for the community supported Metaflow package, this is also *not*\n  it, please see [here](https://github.com/Netflix/metaflow) for that package.\n\nNetflix released Metaflow as OSS in 2019. Since then, development of Metaflow internally\nto Netflix has continued primarily around extensions to better support Netflix's\ninfrastructure and provide a more seamless integration with the compute and orchestration\nplatforms specific to Netflix. Netflix continues to collaboratively improve Metaflow's\nOSS capabilities in collaboration with [OuterBounds](https://outerbounds.co) and,\nas such, sometimes develops functionality that is not yet fully ready for inclusion in\nthe community supported Metaflow, either because it is not fully fleshed out or interest\nin this functionality is not clear. Typically, functionality present here is either\ndeployed actively at Netflix or being tested for deployment at Netflix.\n\nThis repository will contain such functionality. While we do our best to ensure that\nthe functionality present works, it does not have the same levels of support and\nbackward compatibility guarantees that Metaflow does. Functionality present in\nthis package is likely to end up in the main Metaflow package with, potentially,\nsome modification (in which case it will be removed from this package) but that is\nnot a guarantee. If you find this functionality useful and would like to see it make\nit to the main Metaflow package, let us know. Feedback is always welcome!\n\nIf you have any question, feel free to open an issue here or contact us on the usual\nMetaflow slack channels.\n\nThis extension currently contains:\n- refactored [Conda decorator](#conda-v2)\n\n## Conda V2\nThis functionality is currently being actively tested within Netflix but has not yet\nbeen deployed in production.\n\nIt is likely to evolve primarily in its implementation as we do further testing. Feedback\non what is working and what is not is most welcome.\n\n### Improvements over the included Conda decorator\nThis decorator improves several aspects of the included Conda decorator:\n- it has significant performance gains:\n  - resolving environments in parallel\n  - supporting `.conda` packages (instead of only the older `.tar.bz2` packages)\n  - using `micromamba` for environment creation\n- it allows the inclusion of `pypi` packages in the environment specification\n- it is more efficient in its use of caching\n- environment descriptions are also cached allowing anyone to reuse a previously\n  resolved environment\n- it provides more visibility into the environments created\n- it allows you to recreate the environment used for a step locally to aid in\n  accessing the artifacts produced and/or debug the execution of a step.\n\n### Installation\nTo use, simply install this package alongside the `metaflow` package. This package\nrequires Metaflow v2.7.16 or later. This implementation currently only supports S3 for\nenvironment caching. If you require additional datastores, please open an issue and we\ncan work together to add it (it is not very hard).\n\n#### Configuration\nYou have several configuration options that can be set in\n`metaflow_extensions/netflix_ext/config/mfextinit_netflixext.py`. Due to limitations in\nthe OSS implementation of decorators such as `batch` and `kubernetes`, you should\nset these values directly in the configuration file and not in an external configuration\nor through environment variables. The useful configuration values are listed below:\n- `CONDA_S3ROOT`: directory in S3 containing all the cached packages and environments\n  as well as eventual conda distributions to use. For safety, do not point this to the\n  same prefix as for the current Conda implementation.\n- `CONDA_DEPENDENCY_RESOLVER`: `mamba` or `conda`; `mamba` is recommended as\n  typically faster.\n- `CONDA_REMOTE_INSTALLER_DIRNAME`: if set contains a prefix within `CONDA_S3ROOT`\n  under which `micromamba` (or other similar executable) are cached. If not specified,\n  `micromamba`'s latest version will be downloaded on remote environments when an\n  environment needs to be re-hydrated.\n- `CONDA_REMOTE_INSTALLER`: if set architecture specific installer in \n  `CONDA_REMOTE_INSTALLER_DIRNAME`.\n- `CONDA_LOCAL_DIST_DIRNAME`: if set contains a prefix within `CONDA_S3ROOT` under\n  which fully created conda environments for local execution are cached. If not set,\n  the local machine's Conda installation is used.\n- `CONDA_LOCAL_DIST`: if set architecture specific tar ball in `CONDA_LOCAL_DIST_DIRNAME`.\n- `CONDA_LOCAL_PATH`: if set, installs the tarball in `CONDA_LOCAL_DIST` in this path.\n- `CONDA_PREFERRED_FORMAT`: `.tar.bz2` or `.conda`. Prefer `.conda` for speed gains; any\n  package not available in the preferred format will be transmuted to it automatically.\n- `CONDA_PREFERRED_RESOLVER`: `conda` or `conda-lock`; use `conda`/`mamba` or `conda-lock`\n  to resolve environments. `conda-lock` is in more active development but allows for\n  the inclusion of `pypi` dependencies.\n- `CONDA_DEFAULT_PIP_SOURCES`: list of additional mirrors to search for packages. Useful\n  if your company has an internal mirror.\n\n#### Conda environment requirements\nYour local conda environment or the cached environment (in `CONDA_LOCAL_DIST_DIRNAME`)\nneeds to satisfy the following requirements:\n- `conda<22.11` (Conda 22.11+ has issues with `conda-lock`)\n- `conda-lock>=1.3.0`\n- `micromamba>=1.1.0`\n- `conda-package-handling>=1.9.0`\n- `lockfile`\n- (optional but recommended) `mamba>=1.1.0`\n\nIn addition, and only if you want to support `pypi` packages, it is best to apply the\nPR `https://github.com/conda-incubator/conda-lock/pull/290` to `conda-lock`. This is\nthe unfortunate result of a bug in how `conda-lock` handles packages that are both\npresent in the `conda` environment and `pypi` one.\n\nDue to bugs in `conda` and the way we use it, if your resolved environment\ncontains `.conda` packages and you do not have `micromamba` installed, the\nenvironment creation will fail.\n\n#### Uninstallation\nUninstalling this package will revert the behavior of the conda decorator to the one\ncurrently present in Metaflow. It is safe to switch back and forth and there should\nbe no conflict between both implementations provided they do not share the same\ncaching prefix in S3.\n\n### Usage\nYour current code with `conda` decorators will continue working as is. However, at this\ntime, there is no method to \"convert\" previously resolved environment to this new\nimplementation so the first time you run Metaflow with this package, your previously\nresolved environments will be ignored and re-resolved.\n\n#### Additional decorator options\nThe `conda` and `conda_base` decorators take the following additional options:\n- `channels`: A list of additional Conda channels to search. This is useful if the\n  channel is not on `anaconda.org` and cannot be referred to as using the `::` notation.\n- `pip_packages`: A dictionary using the same format as the `libraries` option to\n  specify packages present in `pypi`.\n- `pip_sources`: A list of additional `pypi` repositories.\n- `archs`: A list of strings indicating the architectures to resolve this environment\n  for. By default, the environment is resolved for the current platform and `linux-64`\n  if running on a remote environment.\n\n#### Additional command-line tool\nAn additional `environment` command-line tool is available invoked as follows:\n`python myflow.py --environment=conda environment --help`.\nIt provides the following two sub-commands:\n- `list`: will list all available resolved environments for the steps in the flow.\n  Environonments can be present locally or remotely cached.\n- `select-resolved`: will list all available resolved environments for the steps in\n  the flow and allow you to select which specific resolved environment should be used\n  for each step. This allows you to re-resolve an environment for example (without\n  changing the dependencies -- something not easily possible in the current\n  implementation) as well as select a different environment. Note that once selected,\n  the environment will apply to any step that has the same set of dependencies.\n\nIn both of these commands, by default a menu is used to display the information. You can\ndisable this using `--no-menu`. If using the menu, the list of environments can be\nsorted (use the `~` key) or searched (use the `/` key). Normal up/down/page-up/page-down\nnavigation will also work (if you ever have that many environments).\n\nFinally, the `metaflow` command is also augmented with an `environment` subcommand which\ncurrently only has the `create-local` subcommand which allows you to specify the pathspec\nto a step and it will recreate a local Conda environment duplicating the one present\nfor that step.\n\n### Technical details\nThis section dives a bit more in the technical aspects of this implementation.\n#### General Concepts\n##### Environments\nAn environment can either be un-resolved or resolved. An un-resolved environment is\nsimply defined by the set of high-level user-requirements that the environment must\nsatisfy. Typically, this is a list of Conda and/or Pypi packages and version constraints\non them. In our case, we also include the set of channels (Conda) or sources (Pip).\nA resolved environment contains the concrete list of packages that are to be installed\nto meet the aforementioned requirements. In a resolved environment, all packages are\npinned to a single unique version.\n\nIn Metaflow, two hashes identify environments and `EnvID` (from `env_descr.py`)\nencapsulates these hashes:\n- the set of user requirements are hashed to produce the first hash,\n  the `req_id`. This hash encapsulates the packages and version constraints as well\n  as the channels or sources. The packages are sorted to provide a stable hash for\n  identical set of requirements.\n- the full set of packages needed are hashed to produce the second hash, the `full_id`.\n\nWe also associate the architecture for which the environment was resolved to form the\ncomplete `EnvID`.\n\nEnvironments are named as `metaflow_<req_id>_<full_id>`. Note that environments that\nare resolved versions of the same un-resolved environment therefore have the same\nprefix.\n\n##### Overview of the phases needed to execute a task in a Conda environment\nThis implementation of Conda clearly separates out the phases needed to execute a\nMetaflow task in a Conda environment:\n- resolving the environment: this is the step needed to go from an un-resolved\n  environment to a fully resolved one. It does not require the downloading of packages\n  (for the most part) nor the creation of an environment.\n- caching the environment: this is an optional step which stores all the packages as\n  well as the description of the environment in S3 for later retrieval on environment\n  creation. During this step, packages may be downloaded (from the web for example) but\n  an environment is still not created.\n- creating the environment: in this step, the exact set of packages needed are\n  downloaded (if needed) and an environment is created from there. At this point, there\n  is no resolution (we know the exact set of packages needed).\n\n  ##### Code organization\n  ###### Environment description\n  `env_descr.py` contains a simple way to encode all the information needed for all the\n  above steps, specifically it contains a set of `ResolvedEnvironment` which, in turn,\n  contain the ID for the environment and information about each package. Each package,\n  in turn, contains information about where it can be located on the web as well\n  as caching information (where it is located in the cache). Each package can also\n  support multiple formats (Conda uses either `.tar.bz2` or `.conda` -- note that this\n  is meant to support *equivalent* formats and not `.whl` versus `.tar.gz` for Pypi\n  packages for example).\n\n  Very little effort is made to remove duplicate information (packages may for example\n  be present in several resolved environments) as modularity is favored (ie: each\n  `ResolvedEnvironment` is fully self contained).\n\n  ###### Decorators\n  The `conda_flow_decorator.py` and `conda_step_decorator.py` files simply contain\n  trivial logic to convert the specification passed to those decorators (effectively\n  information needed to construct the requirement ID of the environment) to something\n  that is understandable by the rest of the system. In effect, they are mostly\n  transformers that take user-information and convert it to the set of packages the\n  user wants to have present in their environment.\n\n  ###### Environment\n  The `conda_environment.py` file contains methods to effectively:\n  - resolve all un-resolved environments in a flow\n  - bootstrap Conda environments (this is analogous to some functionality in\n    `conda_step_decorator.py` that has to do with starting a task locally).\n\nThe actual work is all handled in the `conda.py` file which contains the crux of the\nlogic.\n\n##### Detailed description of the phases\n###### Resolving environments\nAll environments are resolved in parallel and independently. To do so, we either use\n`conda-lock` or `mamba/conda` using the `--dry-run` option. The processing\nfor this takes place in `resolve_environment` in the `conda.py` file.\n\nThe input to this step is a set of user-level requirements and the output is a set\nof `ResolvedEnvironment`. At this point, no package has been downloaded and the\n`ResolvedEnvironment` is most likely missing any information about caching.\n\n###### Caching environments\nThe `cache_environments` method in the `conda.py` file implements this.\n\nThere are several steps here. We perform these steps for all resolved environments\nthat need their cache information updated at once to be able to exploit the fact that\nseveral environments may refer to the same package:\n- first we check if we have the packages needed in cache. To do so, the path a package\n  is uploaded to in cache is uniquely determined by its source URL.\n- for all packages that are *not* present in the cache, we will \"download\" them. This\n  is implemented in the `lazy_download_packages` method. We do this per architecture.\n  The basic concept of this function is to locate the \"nearest\" source of the package.\n  In order, we look for:\n  - a locally present archive in some format\n  - a cache present archive in some format\n  - a web present archive in some format.\n  We download the archive and transmute it if needed. The way we do downloads ensures\n  that any downloaded package will be available if we need to create the environments\n  locally. We take care of properly updating the list of URLs if needed (so Conda\n  can reason about what is present in the directory).\n- we then upload all packages to S3 using our parallel uploader. Transmuted packages\n  are also linked together so we can find them later.\n\nThe `ResolvedEnvironment`, now with updated cache information, is also cached to S3 to\npromote sharing.\n\n###### Creating environments\nThis is the easiest step of all and simply consists of fetching all packages (again\nusing the `lazy_download_packages` method which will not download any package that\nis already present) and then using `micromamba` (or `mamba/conda`) to simply install\nall packages.\n\n##### Detailed information about caching\nThere are two main things that are cached:\n- environment themselves (so basically the `ResolvedEnvironment` in JSON format)\n- the packages used in the environments.\n\nThere are also two levels of caching:\n- locally:\n  - Environment descriptions are stored in a special file called `conda_v2.cnd` which\n    caches all environments already resolved. This allows us to reuse the same\n    environment for similar user-level requirements (which is typically what the user\n    wants).\n  - Packages themselves may be cached in the `pkgs` directory of the Conda installation.\n    They may be either fully expanded directories or archives.\n- remotely:\n  - Environment descriptiosn are also stored remotely and can be fetched to be added\n    to the local `conda_v2.cnd` file.\n  - Packages are stored as archived and may be downloaded in the `pkgs` directory. The\n    implementation takes care of properly updating the `urls.txt` file to make it\n    transparent to Conda (allowing it to operate in an \"offline\" mode effectively).\n\n",
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "",
            "keywords": "",
            "license": "",
            "maintainer": "",
            "maintainer_email": "",
            "name": "metaflow-netflixext",
            "package_url": "https://pypi.org/project/metaflow-netflixext/",
            "platform": null,
            "project_url": "https://pypi.org/project/metaflow-netflixext/",
            "project_urls": null,
            "release_url": "https://pypi.org/project/metaflow-netflixext/0.0.2/",
            "requires_dist": [
                "metaflow (>=2.7.16)"
            ],
            "requires_python": ">3.5",
            "summary": "EXPERIMENTAL Metaflow extensions from Netflix",
            "version": "0.0.2",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 16178690,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "1ed9a642049423f31e733aa6f7e094ea",
                    "sha256": "43e9ee4594734575311ec9ec58a968fb9965a887b0beab64c0e725d0f5e4a3f3"
                },
                "downloads": -1,
                "filename": "metaflow_netflixext-0.0.2-py2.py3-none-any.whl",
                "has_sig": false,
                "md5_digest": "1ed9a642049423f31e733aa6f7e094ea",
                "packagetype": "bdist_wheel",
                "python_version": "py2.py3",
                "requires_python": ">3.5",
                "size": 84322,
                "upload_time": "2022-12-22T00:15:37",
                "upload_time_iso_8601": "2022-12-22T00:15:37.331154Z",
                "url": "https://files.pythonhosted.org/packages/1f/13/8f1aeeeb25e292d7ce4ba4ad30b07c77ba8f9b1cab7ecd9653ec89dfefa7/metaflow_netflixext-0.0.2-py2.py3-none-any.whl",
                "yanked": false,
                "yanked_reason": null
            },
            {
                "comment_text": "",
                "digests": {
                    "md5": "c827c2bd2a8f137f9ccfb4e594bfc7ec",
                    "sha256": "78758cf4753397fb66fb77541cccdf93e896558332d007628eace0e98cd7309d"
                },
                "downloads": -1,
                "filename": "metaflow-netflixext-0.0.2.tar.gz",
                "has_sig": false,
                "md5_digest": "c827c2bd2a8f137f9ccfb4e594bfc7ec",
                "packagetype": "sdist",
                "python_version": "source",
                "requires_python": ">3.5",
                "size": 81663,
                "upload_time": "2022-12-22T00:15:38",
                "upload_time_iso_8601": "2022-12-22T00:15:38.689772Z",
                "url": "https://files.pythonhosted.org/packages/ff/db/37a6d0c58d2a3de33de171c788c5efb24171be183c4c9f5139723fe3cf22/metaflow-netflixext-0.0.2.tar.gz",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    }
}
{
    "0.0.1": {
        "info": {
            "author": "",
            "author_email": "",
            "bugtrack_url": null,
            "classifiers": [],
            "description": "# MIDI ETL\n\nThis repository contains an implementation of a modern data stack for building and analyzing MIDI datasets at scale. The stack is composed of several open source technologies, including DBT, Dagster, Trino, and Minio.\n\nDBT (Data Build Tool) is used to transform and optimize MIDI data as it is ingested from various sources into a data warehouse. DBT scripts are used to clean and preprocess the data, extract relevant metadata, and load it into a staging table.\n\nDagster is used to define and execute data pipelines that fetch MIDI data from online sources using web scraping and API calls, and then load the data into the staging table in the data warehouse. It provides a framework for building, testing, and deploying these pipelines in a robust and scalable way.\n\nTrino is used to analyze the MIDI datasets stored in the data warehouse. It provides a distributed SQL query engine that can handle complex queries and large volumes of data efficiently. This allows data analysts and scientists to extract insights and trends from the MIDI datasets.\n\nMinio is used to store and retrieve the MIDI datasets and other data used in the stack. It is a lightweight, scalable object storage solution that can handle large volumes of data.\n\nOverall, this data stack provides a powerful and scalable platform for building and analyzing MIDI datasets. It can be used by data engineers, data scientists, and data analysts to extract insights and trends from music data at scale.\n\n## Prerequisites\n\nBefore you can use this repository, you will need to install the following:\n\n- Docker : Follow the instructions at https://docs.docker.com/get-docker/ to install Docker on your machine.\n- Docker Compose: follow the instructions at https://docs.docker.com/compose/install/ to install Docker Compose.\n\n## Installation\n\nYou can install `midi_etl` using pip:\n\n``` pip install midi_etl ```\n\n## Usage\n\nTo use this repository, follow these steps:\n\n1. Clone the repository to your local machine:\n\n```bash\ngit clone git@gitlab.com:nintorac-audio/midi_etl.git\n```\n\n2. Navigate to the repository directory:\n\n```bash\ncd midi_etl\n```\n\n3. Build and start the Docker containers:\n\n```bash\ndocker-compose up --build\n```\n\nThis will build the Docker containers for the etl platform and deploy all the infra needed to run the project\n\n4. Navigate to [dagit](http://localhost:3000) to initiate jobs \n\n5. Download DBeaver (or your favourite DB IDE) to run queries over your data lake, navigate to [minio](http://localhost:9001) to review the files in your data lake or use pyarrow to load the dataset in python eg.\n\n```python\n# First, import the necessary libraries\nimport pyarrow as pa\nimport pyarrow.parquet as pq\nimport s3fs\nimport duckdb\n\n# Connect to Minio using s3fs\nfs = s3fs.S3FileSystem(\n    anon=False,\n    use_ssl=False,\n    client_kwargs={\n        \"region_name\": \"us-east-1\",\n        \"endpoint_url\": \"http://localhost:9000\",\n        \"aws_access_key_id\": \"minio\",\n        \"aws_secret_access_key\": \"minio123\",\n        \"verify\": False,\n    }\n)\n\n# Create a Parquet dataset for the path \"midi_etl/midi\" in the \"datasets\" bucket\nnote_ons = pq.ParquetDataset(\"midi_etl/midi/note_ons\", filesystem=fs).read()\n\n# Open a connection to a DuckDB database\nconn = duckdb.connect()\n\n# Now you can run SQL queries on the table using the connection\ncursor = conn.cursor()\ncursor.execute(\"SELECT * FROM note_ons LIMIT 10\")\nprint(cursor.fetchall())\n```\n\n### Makefile\n\n`load_env` is a make target that exports variables from a .env file into your local shell\n\n`get_trino_cli` is a make target that downloads the Trino command-line interface (CLI) from a URL. This is then mounted into the trino container to provide CLI Trino access. \n \n## Available Datasets\n\n- [Lakh MIDI Dataset](https://colinraffel.com/projects/lmd/): The Lakh MIDI dataset is a collection of 176,581 MIDI files, 45,129 of which have been matched and aligned to entries in the Million Song Dataset, and is intended for use in large-scale music information retrieval\n\n\n## License\n\nThis repository is licensed under the MIT license. See [LICENSE](LICENSE) for more information.\n\n\n\ngraph TD\n\nA[Lakh MIDI dataset]-H\n\nB[Dagster Daemon] --> C[DBT]\nD --> E[Minio]\nB --> D[Trino]\nC --> D\nB --> F[Process Lakh MIDI dataset]\nB --> G[Process MIDI messages]\nB --> H[Extract files from tar.gz]\nA --> H\nF --> G\nH --> E\n\nsubgraph raw\nend\nsubgraph dagster\n    F\n    G\n    H\nend\n",
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "",
            "keywords": "",
            "license": "",
            "maintainer": "",
            "maintainer_email": "",
            "name": "midi-etl",
            "package_url": "https://pypi.org/project/midi-etl/",
            "platform": null,
            "project_url": "https://pypi.org/project/midi-etl/",
            "project_urls": null,
            "release_url": "https://pypi.org/project/midi-etl/0.0.1/",
            "requires_dist": [
                "mido (==1.2.10)",
                "pandas",
                "requests",
                "pyarrow (>=10)",
                "dagster (==1.1.6)",
                "s3fs",
                "trino",
                "dbt-core",
                "dbt-trino",
                "dagster-dbt",
                "torch-geometric",
                "ray",
                "modin",
                "duckdb",
                "torchdata",
                "pytorch-forecasting"
            ],
            "requires_python": ">=3.10",
            "summary": "Midi ETL pipelines implemented with dagster + dbt",
            "version": "0.0.1",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 16233888,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "0e007c6ec06ce33c01f6048ad0465915",
                    "sha256": "0b6e54f39c4e9e334c21537f1f76c210cd286c209a30343b87e671323c12b426"
                },
                "downloads": -1,
                "filename": "midi_etl-0.0.1-py3-none-any.whl",
                "has_sig": false,
                "md5_digest": "0e007c6ec06ce33c01f6048ad0465915",
                "packagetype": "bdist_wheel",
                "python_version": "py3",
                "requires_python": ">=3.10",
                "size": 12102,
                "upload_time": "2022-12-28T01:58:21",
                "upload_time_iso_8601": "2022-12-28T01:58:21.434660Z",
                "url": "https://files.pythonhosted.org/packages/0a/c0/dcf4eb07714f64f4093af11026db5dbcb9c8839ef3b8b12d47dc949f869d/midi_etl-0.0.1-py3-none-any.whl",
                "yanked": false,
                "yanked_reason": null
            },
            {
                "comment_text": "",
                "digests": {
                    "md5": "500dd72a77f3d011782ce5e958654f6c",
                    "sha256": "c78b9c2ff1fee575f35548713a83d47f19eb2582f08c138de8d67cc8c86e4dbd"
                },
                "downloads": -1,
                "filename": "midi_etl-0.0.1.tar.gz",
                "has_sig": false,
                "md5_digest": "500dd72a77f3d011782ce5e958654f6c",
                "packagetype": "sdist",
                "python_version": "source",
                "requires_python": ">=3.10",
                "size": 7186,
                "upload_time": "2022-12-28T01:58:23",
                "upload_time_iso_8601": "2022-12-28T01:58:23.515704Z",
                "url": "https://files.pythonhosted.org/packages/f1/8b/cd2eefe0dd04b4d131fc04e76343fb8ad654feab187bb5b9e7ca9278e98c/midi_etl-0.0.1.tar.gz",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    }
}
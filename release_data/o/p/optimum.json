{
    "0.0.1": {
        "info": {
            "author": "HuggingFace Inc. Special Ops Team",
            "author_email": "hardware@huggingface.co",
            "bugtrack_url": null,
            "classifiers": [
                "Development Status :: 3 - Alpha",
                "Intended Audience :: Developers",
                "Intended Audience :: Education",
                "Intended Audience :: Science/Research",
                "License :: OSI Approved :: Apache Software License",
                "Operating System :: OS Independent",
                "Programming Language :: Python :: 3.8",
                "Programming Language :: Python :: 3.9",
                "Topic :: Scientific/Engineering :: Artificial Intelligence"
            ],
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://huggingface.co/hardware",
            "keywords": "transformers,quantization,pruning,training,ipu",
            "license": "Apache",
            "maintainer": "",
            "maintainer_email": "",
            "name": "optimum",
            "package_url": "https://pypi.org/project/optimum/",
            "platform": "",
            "project_url": "https://pypi.org/project/optimum/",
            "project_urls": {
                "Homepage": "https://huggingface.co/hardware"
            },
            "release_url": "https://pypi.org/project/optimum/0.0.1/",
            "requires_dist": [
                "coloredlogs",
                "sympy",
                "transformers (>=4.9.2)",
                "torch (>=1.8)",
                "pycocotools ; extra == 'intel'",
                "lpot (>=1.6) ; extra == 'intel'",
                "huggingface-hub ; extra == 'intel'",
                "datasets (>=1.2.1) ; extra == 'intel'",
                "onnx ; extra == 'onnxruntime'",
                "onnxruntime ; extra == 'onnxruntime'"
            ],
            "requires_python": "",
            "summary": "Optimum Library is an extension of the Hugging Face Transformers library, providing a framework to integrate third-party libraries from Hardware Partners and interface with their specific functionality.",
            "version": "0.0.1",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 16200391,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "c0249b862894daac5f2d46ae06a286b9",
                    "sha256": "0cd2e03a9c7a96b0fe95cb31fb27393f34485630cee3a11a373036deafe2320f"
                },
                "downloads": -1,
                "filename": "optimum-0.0.1-py3-none-any.whl",
                "has_sig": false,
                "md5_digest": "c0249b862894daac5f2d46ae06a286b9",
                "packagetype": "bdist_wheel",
                "python_version": "py3",
                "requires_python": null,
                "size": 19254,
                "upload_time": "2021-09-14T11:26:54",
                "upload_time_iso_8601": "2021-09-14T11:26:54.565021Z",
                "url": "https://files.pythonhosted.org/packages/af/3e/0cf8207f79cfd03cccfe99d52ca1af0e8711db9be947e5484fa3435cb052/optimum-0.0.1-py3-none-any.whl",
                "yanked": false,
                "yanked_reason": null
            },
            {
                "comment_text": "",
                "digests": {
                    "md5": "f6080cc3a9c279f29dc7b16a3eea46d8",
                    "sha256": "c282d3471059adc7f5ccc9cc3018a34d5a8c103dff96a137fd1a9df589a93144"
                },
                "downloads": -1,
                "filename": "optimum-0.0.1.tar.gz",
                "has_sig": false,
                "md5_digest": "f6080cc3a9c279f29dc7b16a3eea46d8",
                "packagetype": "sdist",
                "python_version": "source",
                "requires_python": null,
                "size": 13323,
                "upload_time": "2021-09-14T11:26:56",
                "upload_time_iso_8601": "2021-09-14T11:26:56.083267Z",
                "url": "https://files.pythonhosted.org/packages/3d/b4/197fa3fdd296d1a656044cb6b4d0a65e515df17af8107bebcbe601c6e8a5/optimum-0.0.1.tar.gz",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "0.1.0": {
        "info": {
            "author": "HuggingFace Inc. Special Ops Team",
            "author_email": "hardware@huggingface.co",
            "bugtrack_url": null,
            "classifiers": [
                "Development Status :: 3 - Alpha",
                "Intended Audience :: Developers",
                "Intended Audience :: Education",
                "Intended Audience :: Science/Research",
                "License :: OSI Approved :: Apache Software License",
                "Operating System :: OS Independent",
                "Programming Language :: Python :: 3.8",
                "Programming Language :: Python :: 3.9",
                "Topic :: Scientific/Engineering :: Artificial Intelligence"
            ],
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://huggingface.co/hardware",
            "keywords": "transformers,quantization,pruning,training,ipu",
            "license": "Apache",
            "maintainer": "",
            "maintainer_email": "",
            "name": "optimum",
            "package_url": "https://pypi.org/project/optimum/",
            "platform": "",
            "project_url": "https://pypi.org/project/optimum/",
            "project_urls": {
                "Homepage": "https://huggingface.co/hardware"
            },
            "release_url": "https://pypi.org/project/optimum/0.1.0/",
            "requires_dist": null,
            "requires_python": "",
            "summary": "Optimum Library is an extension of the Hugging Face Transformers library, providing a framework to integrate third-party libraries from Hardware Partners and interface with their specific functionality.",
            "version": "0.1.0",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 16200391,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "a00f81330a6e0778210bd2bdd2f12dcc",
                    "sha256": "4b56b3943c953bcdbd5c78ccbc58c51d3f2d76814560b4f7a1adc9f69b544c7f"
                },
                "downloads": -1,
                "filename": "optimum-0.1.0.tar.gz",
                "has_sig": false,
                "md5_digest": "a00f81330a6e0778210bd2bdd2f12dcc",
                "packagetype": "sdist",
                "python_version": "source",
                "requires_python": null,
                "size": 16906,
                "upload_time": "2021-11-05T11:21:32",
                "upload_time_iso_8601": "2021-11-05T11:21:32.833693Z",
                "url": "https://files.pythonhosted.org/packages/04/14/84c32587875cd5be736079326b884865e5456db3d8de2bc444a49b1b326e/optimum-0.1.0.tar.gz",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "0.1.1": {
        "info": {
            "author": "HuggingFace Inc. Special Ops Team",
            "author_email": "hardware@huggingface.co",
            "bugtrack_url": null,
            "classifiers": [
                "Development Status :: 3 - Alpha",
                "Intended Audience :: Developers",
                "Intended Audience :: Education",
                "Intended Audience :: Science/Research",
                "License :: OSI Approved :: Apache Software License",
                "Operating System :: OS Independent",
                "Programming Language :: Python :: 3.8",
                "Programming Language :: Python :: 3.9",
                "Topic :: Scientific/Engineering :: Artificial Intelligence"
            ],
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://huggingface.co/hardware",
            "keywords": "transformers,quantization,pruning,training,ipu",
            "license": "Apache",
            "maintainer": "",
            "maintainer_email": "",
            "name": "optimum",
            "package_url": "https://pypi.org/project/optimum/",
            "platform": "",
            "project_url": "https://pypi.org/project/optimum/",
            "project_urls": {
                "Homepage": "https://huggingface.co/hardware"
            },
            "release_url": "https://pypi.org/project/optimum/0.1.1/",
            "requires_dist": null,
            "requires_python": "",
            "summary": "Optimum Library is an extension of the Hugging Face Transformers library, providing a framework to integrate third-party libraries from Hardware Partners and interface with their specific functionality.",
            "version": "0.1.1",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 16200391,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "d12502d1ab242c6609fd15b533fc10bf",
                    "sha256": "608c925123058fbe9ddfd00671eed727ad74a4e67310e48e87eb6b631f549e94"
                },
                "downloads": -1,
                "filename": "optimum-0.1.1.tar.gz",
                "has_sig": false,
                "md5_digest": "d12502d1ab242c6609fd15b533fc10bf",
                "packagetype": "sdist",
                "python_version": "source",
                "requires_python": null,
                "size": 17138,
                "upload_time": "2021-11-05T18:20:15",
                "upload_time_iso_8601": "2021-11-05T18:20:15.808248Z",
                "url": "https://files.pythonhosted.org/packages/79/6d/a628d409e636568e9c5bf9635375601969e822afd9de98e600f3d0d16e46/optimum-0.1.1.tar.gz",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "0.1.2": {
        "info": {
            "author": "HuggingFace Inc. Special Ops Team",
            "author_email": "hardware@huggingface.co",
            "bugtrack_url": null,
            "classifiers": [
                "Development Status :: 3 - Alpha",
                "Intended Audience :: Developers",
                "Intended Audience :: Education",
                "Intended Audience :: Science/Research",
                "License :: OSI Approved :: Apache Software License",
                "Operating System :: OS Independent",
                "Programming Language :: Python :: 3.8",
                "Programming Language :: Python :: 3.9",
                "Topic :: Scientific/Engineering :: Artificial Intelligence"
            ],
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://huggingface.co/hardware",
            "keywords": "transformers,quantization,pruning,training,ipu",
            "license": "Apache",
            "maintainer": "",
            "maintainer_email": "",
            "name": "optimum",
            "package_url": "https://pypi.org/project/optimum/",
            "platform": "",
            "project_url": "https://pypi.org/project/optimum/",
            "project_urls": {
                "Homepage": "https://huggingface.co/hardware"
            },
            "release_url": "https://pypi.org/project/optimum/0.1.2/",
            "requires_dist": [
                "coloredlogs",
                "sympy",
                "transformers (>=4.12.0)",
                "torch (>=1.9)",
                "optimum-graphcore ; extra == 'graphcore'",
                "pycocotools ; extra == 'intel'",
                "neural-compressor (>=1.7) ; extra == 'intel'",
                "datasets (>=1.2.1) ; extra == 'intel'",
                "onnx ; extra == 'onnxruntime'",
                "onnxruntime ; extra == 'onnxruntime'"
            ],
            "requires_python": "",
            "summary": "Optimum Library is an extension of the Hugging Face Transformers library, providing a framework to integrate third-party libraries from Hardware Partners and interface with their specific functionality.",
            "version": "0.1.2",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 16200391,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "cd57bb155f2e35b77a073ca49a2d30ce",
                    "sha256": "141d3549e926b88e049a1c2837a2a8f3ef150c5fd1baf34ff51a0b14a5bfd65b"
                },
                "downloads": -1,
                "filename": "optimum-0.1.2-py3-none-any.whl",
                "has_sig": false,
                "md5_digest": "cd57bb155f2e35b77a073ca49a2d30ce",
                "packagetype": "bdist_wheel",
                "python_version": "py3",
                "requires_python": null,
                "size": 33379,
                "upload_time": "2021-12-08T15:17:54",
                "upload_time_iso_8601": "2021-12-08T15:17:54.874298Z",
                "url": "https://files.pythonhosted.org/packages/5b/25/265c348d2e1b5361871b3767e269801613b8225e303512de86329f71a4ba/optimum-0.1.2-py3-none-any.whl",
                "yanked": false,
                "yanked_reason": null
            },
            {
                "comment_text": "",
                "digests": {
                    "md5": "80973def135189e388fa8da1bbbab7a0",
                    "sha256": "0104bd890e4f29651e5771f0849be994946082782061695abb79147ef1f18462"
                },
                "downloads": -1,
                "filename": "optimum-0.1.2.tar.gz",
                "has_sig": false,
                "md5_digest": "80973def135189e388fa8da1bbbab7a0",
                "packagetype": "sdist",
                "python_version": "source",
                "requires_python": null,
                "size": 29004,
                "upload_time": "2021-12-08T15:17:57",
                "upload_time_iso_8601": "2021-12-08T15:17:57.646608Z",
                "url": "https://files.pythonhosted.org/packages/2f/fd/1e6be3fd65b6107cfcaf9e7523333bc64c96e49faf96a59be3d1eaa8bb67/optimum-0.1.2.tar.gz",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "0.1.3": {
        "info": {
            "author": "HuggingFace Inc. Special Ops Team",
            "author_email": "hardware@huggingface.co",
            "bugtrack_url": null,
            "classifiers": [
                "Development Status :: 3 - Alpha",
                "Intended Audience :: Developers",
                "Intended Audience :: Education",
                "Intended Audience :: Science/Research",
                "License :: OSI Approved :: Apache Software License",
                "Operating System :: OS Independent",
                "Programming Language :: Python :: 3.8",
                "Programming Language :: Python :: 3.9",
                "Topic :: Scientific/Engineering :: Artificial Intelligence"
            ],
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://huggingface.co/hardware",
            "keywords": "transformers,quantization,pruning,training,ipu",
            "license": "Apache",
            "maintainer": "",
            "maintainer_email": "",
            "name": "optimum",
            "package_url": "https://pypi.org/project/optimum/",
            "platform": "",
            "project_url": "https://pypi.org/project/optimum/",
            "project_urls": {
                "Homepage": "https://huggingface.co/hardware"
            },
            "release_url": "https://pypi.org/project/optimum/0.1.3/",
            "requires_dist": [
                "coloredlogs",
                "sympy",
                "transformers (>=4.12.0)",
                "torch (>=1.9)",
                "optimum-graphcore ; extra == 'graphcore'",
                "pycocotools ; extra == 'intel'",
                "neural-compressor (>=1.7) ; extra == 'intel'",
                "datasets (>=1.2.1) ; extra == 'intel'",
                "onnx ; extra == 'onnxruntime'",
                "onnxruntime ; extra == 'onnxruntime'"
            ],
            "requires_python": "",
            "summary": "Optimum Library is an extension of the Hugging Face Transformers library, providing a framework to integrate third-party libraries from Hardware Partners and interface with their specific functionality.",
            "version": "0.1.3",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 16200391,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "491204563f00c3175835c18e161c65a7",
                    "sha256": "535f2f843bf128d3530ff4b285d3d14080d276643ef0a4063a3c80566f563425"
                },
                "downloads": -1,
                "filename": "optimum-0.1.3-py3-none-any.whl",
                "has_sig": false,
                "md5_digest": "491204563f00c3175835c18e161c65a7",
                "packagetype": "bdist_wheel",
                "python_version": "py3",
                "requires_python": null,
                "size": 41830,
                "upload_time": "2021-12-23T09:36:24",
                "upload_time_iso_8601": "2021-12-23T09:36:24.143775Z",
                "url": "https://files.pythonhosted.org/packages/a6/5b/2581e94dbdf0d66b61c3007ccd645e1162874d4afe7902c60f2772dbf8fd/optimum-0.1.3-py3-none-any.whl",
                "yanked": false,
                "yanked_reason": null
            },
            {
                "comment_text": "",
                "digests": {
                    "md5": "bc81f67dd5b15e2c0e522f54a0b5773a",
                    "sha256": "8b480bb8c80af5df16e55b1f71fa7f0975c22e7a5b961f9fcce957de06e7cc92"
                },
                "downloads": -1,
                "filename": "optimum-0.1.3.tar.gz",
                "has_sig": false,
                "md5_digest": "bc81f67dd5b15e2c0e522f54a0b5773a",
                "packagetype": "sdist",
                "python_version": "source",
                "requires_python": null,
                "size": 34183,
                "upload_time": "2021-12-23T09:36:25",
                "upload_time_iso_8601": "2021-12-23T09:36:25.699493Z",
                "url": "https://files.pythonhosted.org/packages/33/e5/0f5d3bd86fb56c645a2f51d8f64517ab658ffd26cee6bda3628b6d4c5133/optimum-0.1.3.tar.gz",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "1.0.0": {
        "info": {
            "author": "HuggingFace Inc. Special Ops Team",
            "author_email": "hardware@huggingface.co",
            "bugtrack_url": null,
            "classifiers": [
                "Development Status :: 3 - Alpha",
                "Intended Audience :: Developers",
                "Intended Audience :: Education",
                "Intended Audience :: Science/Research",
                "License :: OSI Approved :: Apache Software License",
                "Operating System :: OS Independent",
                "Programming Language :: Python :: 3.8",
                "Programming Language :: Python :: 3.9",
                "Topic :: Scientific/Engineering :: Artificial Intelligence"
            ],
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://huggingface.co/hardware",
            "keywords": "transformers,quantization,pruning,training,ipu",
            "license": "Apache",
            "maintainer": "",
            "maintainer_email": "",
            "name": "optimum",
            "package_url": "https://pypi.org/project/optimum/",
            "platform": "",
            "project_url": "https://pypi.org/project/optimum/",
            "project_urls": {
                "Homepage": "https://huggingface.co/hardware"
            },
            "release_url": "https://pypi.org/project/optimum/1.0.0/",
            "requires_dist": null,
            "requires_python": "",
            "summary": "Optimum Library is an extension of the Hugging Face Transformers library, providing a framework to integrate third-party libraries from Hardware Partners and interface with their specific functionality.",
            "version": "1.0.0",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 16200391,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "d74b4ecfeb19f3531e0bc6d0cd6cfb3c",
                    "sha256": "b51c54c47d7ff0f800cc7dfb833074292e4f3637df8494fe97c48cc382094c7d"
                },
                "downloads": -1,
                "filename": "optimum-1.0.0.tar.gz",
                "has_sig": false,
                "md5_digest": "d74b4ecfeb19f3531e0bc6d0cd6cfb3c",
                "packagetype": "sdist",
                "python_version": "source",
                "requires_python": null,
                "size": 46675,
                "upload_time": "2022-02-23T17:49:17",
                "upload_time_iso_8601": "2022-02-23T17:49:17.323754Z",
                "url": "https://files.pythonhosted.org/packages/88/55/190183564e46bbad3c82799dc35b522d3c4da5f0d74b3dd602a83d011f9e/optimum-1.0.0.tar.gz",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "1.1.0": {
        "info": {
            "author": "HuggingFace Inc. Special Ops Team",
            "author_email": "hardware@huggingface.co",
            "bugtrack_url": null,
            "classifiers": [
                "Development Status :: 3 - Alpha",
                "Intended Audience :: Developers",
                "Intended Audience :: Education",
                "Intended Audience :: Science/Research",
                "License :: OSI Approved :: Apache Software License",
                "Operating System :: OS Independent",
                "Programming Language :: Python :: 3.8",
                "Programming Language :: Python :: 3.9",
                "Topic :: Scientific/Engineering :: Artificial Intelligence"
            ],
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://huggingface.co/hardware",
            "keywords": "transformers,quantization,pruning,training,ipu",
            "license": "Apache",
            "maintainer": "",
            "maintainer_email": "",
            "name": "optimum",
            "package_url": "https://pypi.org/project/optimum/",
            "platform": null,
            "project_url": "https://pypi.org/project/optimum/",
            "project_urls": {
                "Homepage": "https://huggingface.co/hardware"
            },
            "release_url": "https://pypi.org/project/optimum/1.1.0/",
            "requires_dist": null,
            "requires_python": "",
            "summary": "Optimum Library is an extension of the Hugging Face Transformers library, providing a framework to integrate third-party libraries from Hardware Partners and interface with their specific functionality.",
            "version": "1.1.0",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 16200391,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "acf33e18730a2575d5f5ce715a2774cb",
                    "sha256": "e4d841115dce38467522c4364a2d00e884a64088b69243aec9c89c12d20242a4"
                },
                "downloads": -1,
                "filename": "optimum-1.1.0.tar.gz",
                "has_sig": false,
                "md5_digest": "acf33e18730a2575d5f5ce715a2774cb",
                "packagetype": "sdist",
                "python_version": "source",
                "requires_python": null,
                "size": 62814,
                "upload_time": "2022-04-01T11:55:22",
                "upload_time_iso_8601": "2022-04-01T11:55:22.458460Z",
                "url": "https://files.pythonhosted.org/packages/1d/4c/b63b1efb9f0a25fcadca3eb11d7091f84da2ba59f9c1c49334bdc3c92c01/optimum-1.1.0.tar.gz",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "1.1.1": {
        "info": {
            "author": "HuggingFace Inc. Special Ops Team",
            "author_email": "hardware@huggingface.co",
            "bugtrack_url": null,
            "classifiers": [
                "Development Status :: 5 - Production/Stable",
                "Intended Audience :: Developers",
                "Intended Audience :: Education",
                "Intended Audience :: Science/Research",
                "License :: OSI Approved :: Apache Software License",
                "Operating System :: OS Independent",
                "Programming Language :: Python :: 3.8",
                "Programming Language :: Python :: 3.9",
                "Topic :: Scientific/Engineering :: Artificial Intelligence"
            ],
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/huggingface/optimum",
            "keywords": "transformers,quantization,pruning,optimization,training,inference,onnx,onnx runtime,intel,habana,graphcore,neural compressor,ipu,hpu",
            "license": "Apache",
            "maintainer": "",
            "maintainer_email": "",
            "name": "optimum",
            "package_url": "https://pypi.org/project/optimum/",
            "platform": null,
            "project_url": "https://pypi.org/project/optimum/",
            "project_urls": {
                "Homepage": "https://github.com/huggingface/optimum"
            },
            "release_url": "https://pypi.org/project/optimum/1.1.1/",
            "requires_dist": null,
            "requires_python": "",
            "summary": "Optimum Library is an extension of the Hugging Face Transformers library, providing a framework to integrate third-party libraries from Hardware Partners and interface with their specific functionality.",
            "version": "1.1.1",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 16200391,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "a8f594de4b9f774d6f8767f791398048",
                    "sha256": "7fe1fd0764ca27f4f5184ab3b0bbcb582195a14a5f8ebbba4fa42b1469350269"
                },
                "downloads": -1,
                "filename": "optimum-1.1.1.tar.gz",
                "has_sig": false,
                "md5_digest": "a8f594de4b9f774d6f8767f791398048",
                "packagetype": "sdist",
                "python_version": "source",
                "requires_python": null,
                "size": 66451,
                "upload_time": "2022-04-26T13:21:08",
                "upload_time_iso_8601": "2022-04-26T13:21:08.342979Z",
                "url": "https://files.pythonhosted.org/packages/a5/05/4f31c8ff3b01f8d99a6352528d221210341bf4b38859e8747cfc19c5cd9d/optimum-1.1.1.tar.gz",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "1.2.0": {
        "info": {
            "author": "HuggingFace Inc. Special Ops Team",
            "author_email": "hardware@huggingface.co",
            "bugtrack_url": null,
            "classifiers": [
                "Development Status :: 5 - Production/Stable",
                "Intended Audience :: Developers",
                "Intended Audience :: Education",
                "Intended Audience :: Science/Research",
                "License :: OSI Approved :: Apache Software License",
                "Operating System :: OS Independent",
                "Programming Language :: Python :: 3.8",
                "Programming Language :: Python :: 3.9",
                "Topic :: Scientific/Engineering :: Artificial Intelligence"
            ],
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/huggingface/optimum",
            "keywords": "transformers,quantization,pruning,optimization,training,inference,onnx,onnx runtime,intel,habana,graphcore,neural compressor,ipu,hpu",
            "license": "Apache",
            "maintainer": "",
            "maintainer_email": "",
            "name": "optimum",
            "package_url": "https://pypi.org/project/optimum/",
            "platform": null,
            "project_url": "https://pypi.org/project/optimum/",
            "project_urls": {
                "Homepage": "https://github.com/huggingface/optimum"
            },
            "release_url": "https://pypi.org/project/optimum/1.2.0/",
            "requires_dist": null,
            "requires_python": ">=3.8.0",
            "summary": "Optimum Library is an extension of the Hugging Face Transformers library, providing a framework to integrate third-party libraries from Hardware Partners and interface with their specific functionality.",
            "version": "1.2.0",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 16200391,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "c70c2c4cd33eae441660fc7d352cd401",
                    "sha256": "c395f22af58f250aa95eaa1742a9e95a8c76624a87efe7ddeb99cd94b1b99cf4"
                },
                "downloads": -1,
                "filename": "optimum-1.2.0.tar.gz",
                "has_sig": false,
                "md5_digest": "c70c2c4cd33eae441660fc7d352cd401",
                "packagetype": "sdist",
                "python_version": "source",
                "requires_python": ">=3.8.0",
                "size": 75531,
                "upload_time": "2022-05-10T13:11:49",
                "upload_time_iso_8601": "2022-05-10T13:11:49.246954Z",
                "url": "https://files.pythonhosted.org/packages/67/88/b6beeac14b28edc8e004ea904b08f2bcf4a7818e52d8937e68da16d12e86/optimum-1.2.0.tar.gz",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "1.2.1": {
        "info": {
            "author": "HuggingFace Inc. Special Ops Team",
            "author_email": "hardware@huggingface.co",
            "bugtrack_url": null,
            "classifiers": [
                "Development Status :: 5 - Production/Stable",
                "Intended Audience :: Developers",
                "Intended Audience :: Education",
                "Intended Audience :: Science/Research",
                "License :: OSI Approved :: Apache Software License",
                "Operating System :: OS Independent",
                "Programming Language :: Python :: 3.7",
                "Programming Language :: Python :: 3.8",
                "Programming Language :: Python :: 3.9",
                "Topic :: Scientific/Engineering :: Artificial Intelligence"
            ],
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/huggingface/optimum",
            "keywords": "transformers,quantization,pruning,optimization,training,inference,onnx,onnx runtime,intel,habana,graphcore,neural compressor,ipu,hpu",
            "license": "Apache",
            "maintainer": "",
            "maintainer_email": "",
            "name": "optimum",
            "package_url": "https://pypi.org/project/optimum/",
            "platform": null,
            "project_url": "https://pypi.org/project/optimum/",
            "project_urls": {
                "Homepage": "https://github.com/huggingface/optimum"
            },
            "release_url": "https://pypi.org/project/optimum/1.2.1/",
            "requires_dist": null,
            "requires_python": ">=3.7.0",
            "summary": "Optimum Library is an extension of the Hugging Face Transformers library, providing a framework to integrate third-party libraries from Hardware Partners and interface with their specific functionality.",
            "version": "1.2.1",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 16200391,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "a3047d2a684d0397b935911eb41a5ab0",
                    "sha256": "0b0bc4d8c20e6c85095c49dd0fc9ea5754620af8b162ab460820af7081efdf84"
                },
                "downloads": -1,
                "filename": "optimum-1.2.1.tar.gz",
                "has_sig": false,
                "md5_digest": "a3047d2a684d0397b935911eb41a5ab0",
                "packagetype": "sdist",
                "python_version": "source",
                "requires_python": ">=3.7.0",
                "size": 75564,
                "upload_time": "2022-05-12T08:25:44",
                "upload_time_iso_8601": "2022-05-12T08:25:44.227063Z",
                "url": "https://files.pythonhosted.org/packages/93/6e/f96bd191ad0f7aae00a9830a7f3621626e4e0a4dc2488ed2fa59c3c5962f/optimum-1.2.1.tar.gz",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "1.2.2": {
        "info": {
            "author": "HuggingFace Inc. Special Ops Team",
            "author_email": "hardware@huggingface.co",
            "bugtrack_url": null,
            "classifiers": [
                "Development Status :: 5 - Production/Stable",
                "Intended Audience :: Developers",
                "Intended Audience :: Education",
                "Intended Audience :: Science/Research",
                "License :: OSI Approved :: Apache Software License",
                "Operating System :: OS Independent",
                "Programming Language :: Python :: 3.7",
                "Programming Language :: Python :: 3.8",
                "Programming Language :: Python :: 3.9",
                "Topic :: Scientific/Engineering :: Artificial Intelligence"
            ],
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/huggingface/optimum",
            "keywords": "transformers,quantization,pruning,optimization,training,inference,onnx,onnx runtime,intel,habana,graphcore,neural compressor,ipu,hpu",
            "license": "Apache",
            "maintainer": "",
            "maintainer_email": "",
            "name": "optimum",
            "package_url": "https://pypi.org/project/optimum/",
            "platform": null,
            "project_url": "https://pypi.org/project/optimum/",
            "project_urls": {
                "Homepage": "https://github.com/huggingface/optimum"
            },
            "release_url": "https://pypi.org/project/optimum/1.2.2/",
            "requires_dist": null,
            "requires_python": ">=3.7.0",
            "summary": "Optimum Library is an extension of the Hugging Face Transformers library, providing a framework to integrate third-party libraries from Hardware Partners and interface with their specific functionality.",
            "version": "1.2.2",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 16200391,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "5ac73595339508449c9a8aae4dfc50f0",
                    "sha256": "9c334507ad6d54cf11b71892a2af98721329f7b50057fd180465eacf5ed51146"
                },
                "downloads": -1,
                "filename": "optimum-1.2.2.tar.gz",
                "has_sig": false,
                "md5_digest": "5ac73595339508449c9a8aae4dfc50f0",
                "packagetype": "sdist",
                "python_version": "source",
                "requires_python": ">=3.7.0",
                "size": 88788,
                "upload_time": "2022-06-02T10:05:17",
                "upload_time_iso_8601": "2022-06-02T10:05:17.829800Z",
                "url": "https://files.pythonhosted.org/packages/6f/46/7e629c642bd83aeecc9b56aa56c804fc244a06a490e8e4e9efea009f8b61/optimum-1.2.2.tar.gz",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "1.2.3": {
        "info": {
            "author": "HuggingFace Inc. Special Ops Team",
            "author_email": "hardware@huggingface.co",
            "bugtrack_url": null,
            "classifiers": [
                "Development Status :: 5 - Production/Stable",
                "Intended Audience :: Developers",
                "Intended Audience :: Education",
                "Intended Audience :: Science/Research",
                "License :: OSI Approved :: Apache Software License",
                "Operating System :: OS Independent",
                "Programming Language :: Python :: 3.7",
                "Programming Language :: Python :: 3.8",
                "Programming Language :: Python :: 3.9",
                "Topic :: Scientific/Engineering :: Artificial Intelligence"
            ],
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/huggingface/optimum",
            "keywords": "transformers,quantization,pruning,optimization,training,inference,onnx,onnx runtime,intel,habana,graphcore,neural compressor,ipu,hpu",
            "license": "Apache",
            "maintainer": "",
            "maintainer_email": "",
            "name": "optimum",
            "package_url": "https://pypi.org/project/optimum/",
            "platform": null,
            "project_url": "https://pypi.org/project/optimum/",
            "project_urls": {
                "Homepage": "https://github.com/huggingface/optimum"
            },
            "release_url": "https://pypi.org/project/optimum/1.2.3/",
            "requires_dist": null,
            "requires_python": ">=3.7.0",
            "summary": "Optimum Library is an extension of the Hugging Face Transformers library, providing a framework to integrate third-party libraries from Hardware Partners and interface with their specific functionality.",
            "version": "1.2.3",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 16200391,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "9abcc7a705bb1bf42aaea07f5cf3eb79",
                    "sha256": "d1151ad2e7e5f855df9831bf53e6da14d64dab5179a6175de9c673dcc39f76fd"
                },
                "downloads": -1,
                "filename": "optimum-1.2.3.tar.gz",
                "has_sig": false,
                "md5_digest": "9abcc7a705bb1bf42aaea07f5cf3eb79",
                "packagetype": "sdist",
                "python_version": "source",
                "requires_python": ">=3.7.0",
                "size": 75995,
                "upload_time": "2022-06-13T16:24:55",
                "upload_time_iso_8601": "2022-06-13T16:24:55.750227Z",
                "url": "https://files.pythonhosted.org/packages/29/42/b98b08b7c7ec949211cafd3f1b6dd1d0ea5ef09ac6cefd99c72fcb515ef6/optimum-1.2.3.tar.gz",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "1.3.0": {
        "info": {
            "author": "HuggingFace Inc. Special Ops Team",
            "author_email": "hardware@huggingface.co",
            "bugtrack_url": null,
            "classifiers": [
                "Development Status :: 5 - Production/Stable",
                "Intended Audience :: Developers",
                "Intended Audience :: Education",
                "Intended Audience :: Science/Research",
                "License :: OSI Approved :: Apache Software License",
                "Operating System :: OS Independent",
                "Programming Language :: Python :: 3.7",
                "Programming Language :: Python :: 3.8",
                "Programming Language :: Python :: 3.9",
                "Topic :: Scientific/Engineering :: Artificial Intelligence"
            ],
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/huggingface/optimum",
            "keywords": "transformers,quantization,pruning,optimization,training,inference,onnx,onnx runtime,intel,habana,graphcore,neural compressor,ipu,hpu",
            "license": "Apache",
            "maintainer": "",
            "maintainer_email": "",
            "name": "optimum",
            "package_url": "https://pypi.org/project/optimum/",
            "platform": null,
            "project_url": "https://pypi.org/project/optimum/",
            "project_urls": {
                "Homepage": "https://github.com/huggingface/optimum"
            },
            "release_url": "https://pypi.org/project/optimum/1.3.0/",
            "requires_dist": null,
            "requires_python": ">=3.7.0",
            "summary": "Optimum Library is an extension of the Hugging Face Transformers library, providing a framework to integrate third-party libraries from Hardware Partners and interface with their specific functionality.",
            "version": "1.3.0",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 16200391,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "3c8d920f124b3f11336fbc5fcff9ac09",
                    "sha256": "e68a7a075571cfadf3eaa02513cfdd315f750ce01e8ed5b8d3b4ce785b5c9c7d"
                },
                "downloads": -1,
                "filename": "optimum-1.3.0.tar.gz",
                "has_sig": false,
                "md5_digest": "3c8d920f124b3f11336fbc5fcff9ac09",
                "packagetype": "sdist",
                "python_version": "source",
                "requires_python": ">=3.7.0",
                "size": 93426,
                "upload_time": "2022-07-12T12:02:23",
                "upload_time_iso_8601": "2022-07-12T12:02:23.657826Z",
                "url": "https://files.pythonhosted.org/packages/17/ca/937aa691c28357069d4e17bb628aaad6da552b1615e449b09f72d94d98fb/optimum-1.3.0.tar.gz",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "1.4.0": {
        "info": {
            "author": "HuggingFace Inc. Special Ops Team",
            "author_email": "hardware@huggingface.co",
            "bugtrack_url": null,
            "classifiers": [
                "Development Status :: 5 - Production/Stable",
                "Intended Audience :: Developers",
                "Intended Audience :: Education",
                "Intended Audience :: Science/Research",
                "License :: OSI Approved :: Apache Software License",
                "Operating System :: OS Independent",
                "Programming Language :: Python :: 3.7",
                "Programming Language :: Python :: 3.8",
                "Programming Language :: Python :: 3.9",
                "Topic :: Scientific/Engineering :: Artificial Intelligence"
            ],
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/huggingface/optimum",
            "keywords": "transformers,quantization,pruning,optimization,training,inference,onnx,onnx runtime,intel,habana,graphcore,neural compressor,ipu,hpu",
            "license": "Apache",
            "maintainer": "",
            "maintainer_email": "",
            "name": "optimum",
            "package_url": "https://pypi.org/project/optimum/",
            "platform": null,
            "project_url": "https://pypi.org/project/optimum/",
            "project_urls": {
                "Homepage": "https://github.com/huggingface/optimum"
            },
            "release_url": "https://pypi.org/project/optimum/1.4.0/",
            "requires_dist": null,
            "requires_python": ">=3.7.0",
            "summary": "Optimum Library is an extension of the Hugging Face Transformers library, providing a framework to integrate third-party libraries from Hardware Partners and interface with their specific functionality.",
            "version": "1.4.0",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 16200391,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "4fdb37bb6884ed7aeb91e54a10adc986",
                    "sha256": "29b0d41805601eb11302488eb7eae7f60a0fe362be3726e29d448587a4403e62"
                },
                "downloads": -1,
                "filename": "optimum-1.4.0.tar.gz",
                "has_sig": false,
                "md5_digest": "4fdb37bb6884ed7aeb91e54a10adc986",
                "packagetype": "sdist",
                "python_version": "source",
                "requires_python": ">=3.7.0",
                "size": 101663,
                "upload_time": "2022-09-08T17:53:35",
                "upload_time_iso_8601": "2022-09-08T17:53:35.634999Z",
                "url": "https://files.pythonhosted.org/packages/93/b9/72e9cbfc681ec99f21d69f8c0ab16204e9a4362ac1931df3000ed3dc1bf2/optimum-1.4.0.tar.gz",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "1.4.1": {
        "info": {
            "author": "HuggingFace Inc. Special Ops Team",
            "author_email": "hardware@huggingface.co",
            "bugtrack_url": null,
            "classifiers": [
                "Development Status :: 5 - Production/Stable",
                "Intended Audience :: Developers",
                "Intended Audience :: Education",
                "Intended Audience :: Science/Research",
                "License :: OSI Approved :: Apache Software License",
                "Operating System :: OS Independent",
                "Programming Language :: Python :: 3.7",
                "Programming Language :: Python :: 3.8",
                "Programming Language :: Python :: 3.9",
                "Topic :: Scientific/Engineering :: Artificial Intelligence"
            ],
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/huggingface/optimum",
            "keywords": "transformers,quantization,pruning,optimization,training,inference,onnx,onnx runtime,intel,habana,graphcore,neural compressor,ipu,hpu",
            "license": "Apache",
            "maintainer": "",
            "maintainer_email": "",
            "name": "optimum",
            "package_url": "https://pypi.org/project/optimum/",
            "platform": null,
            "project_url": "https://pypi.org/project/optimum/",
            "project_urls": {
                "Homepage": "https://github.com/huggingface/optimum"
            },
            "release_url": "https://pypi.org/project/optimum/1.4.1/",
            "requires_dist": null,
            "requires_python": ">=3.7.0",
            "summary": "Optimum Library is an extension of the Hugging Face Transformers library, providing a framework to integrate third-party libraries from Hardware Partners and interface with their specific functionality.",
            "version": "1.4.1",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 16200391,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "1c67169cf4769444b0a6e9d3b8db76d5",
                    "sha256": "f10fdc4e1a9045a375ec78ffd66aad006458d96dbd378e8a5fe0ee997ee10903"
                },
                "downloads": -1,
                "filename": "optimum-1.4.1.tar.gz",
                "has_sig": false,
                "md5_digest": "1c67169cf4769444b0a6e9d3b8db76d5",
                "packagetype": "sdist",
                "python_version": "source",
                "requires_python": ">=3.7.0",
                "size": 111324,
                "upload_time": "2022-10-25T17:45:21",
                "upload_time_iso_8601": "2022-10-25T17:45:21.031833Z",
                "url": "https://files.pythonhosted.org/packages/df/82/8b9728334e3f7e8bd3b7839af2787735bb69de51342d05ea5b4de9573e9c/optimum-1.4.1.tar.gz",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "1.5.0": {
        "info": {
            "author": "HuggingFace Inc. Special Ops Team",
            "author_email": "hardware@huggingface.co",
            "bugtrack_url": null,
            "classifiers": [
                "Development Status :: 5 - Production/Stable",
                "Intended Audience :: Developers",
                "Intended Audience :: Education",
                "Intended Audience :: Science/Research",
                "License :: OSI Approved :: Apache Software License",
                "Operating System :: OS Independent",
                "Programming Language :: Python :: 3.7",
                "Programming Language :: Python :: 3.8",
                "Programming Language :: Python :: 3.9",
                "Topic :: Scientific/Engineering :: Artificial Intelligence"
            ],
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/huggingface/optimum",
            "keywords": "transformers,quantization,pruning,optimization,training,inference,onnx,onnx runtime,intel,habana,graphcore,neural compressor,ipu,hpu",
            "license": "Apache",
            "maintainer": "",
            "maintainer_email": "",
            "name": "optimum",
            "package_url": "https://pypi.org/project/optimum/",
            "platform": null,
            "project_url": "https://pypi.org/project/optimum/",
            "project_urls": {
                "Homepage": "https://github.com/huggingface/optimum"
            },
            "release_url": "https://pypi.org/project/optimum/1.5.0/",
            "requires_dist": [
                "coloredlogs",
                "sympy",
                "transformers[sentencepiece] (>=4.20.1)",
                "torch (>=1.9)",
                "packaging",
                "numpy",
                "huggingface-hub (>=0.8.0)",
                "optuna ; extra == 'benchmark'",
                "tqdm ; extra == 'benchmark'",
                "sklearn ; extra == 'benchmark'",
                "seqeval ; extra == 'benchmark'",
                "torchvision ; extra == 'benchmark'",
                "evaluate (>=0.2.0) ; extra == 'benchmark'",
                "pytest ; extra == 'dev'",
                "requests ; extra == 'dev'",
                "parameterized ; extra == 'dev'",
                "pytest-xdist ; extra == 'dev'",
                "Pillow ; extra == 'dev'",
                "black (~=22.0) ; extra == 'dev'",
                "flake8 (>=3.8.3) ; extra == 'dev'",
                "isort (>=5.5.4) ; extra == 'dev'",
                "onnx ; extra == 'exporters'",
                "onnxruntime ; extra == 'exporters'",
                "timm ; extra == 'exporters'",
                "tensorflow ; extra == 'exporters-tf'",
                "tf2onnx ; extra == 'exporters-tf'",
                "onnx ; extra == 'exporters-tf'",
                "onnxruntime ; extra == 'exporters-tf'",
                "timm ; extra == 'exporters-tf'",
                "optimum-graphcore ; extra == 'graphcore'",
                "optimum-habana ; extra == 'habana'",
                "optimum-intel ; extra == 'intel'",
                "optimum-intel[neural-compressor] ; extra == 'neural-compressor'",
                "optimum-intel[nncf] ; extra == 'nncf'",
                "onnx ; extra == 'onnxruntime'",
                "onnxruntime (>=1.9.0) ; extra == 'onnxruntime'",
                "datasets (>=1.2.1) ; extra == 'onnxruntime'",
                "evaluate ; extra == 'onnxruntime'",
                "protobuf (==3.20.1) ; extra == 'onnxruntime'",
                "onnx ; extra == 'onnxruntime-gpu'",
                "onnxruntime-gpu (>=1.9.0) ; extra == 'onnxruntime-gpu'",
                "datasets (>=1.2.1) ; extra == 'onnxruntime-gpu'",
                "evaluate ; extra == 'onnxruntime-gpu'",
                "protobuf (==3.20.1) ; extra == 'onnxruntime-gpu'",
                "optimum-intel[openvino] ; extra == 'openvino'",
                "black (~=22.0) ; extra == 'quality'",
                "flake8 (>=3.8.3) ; extra == 'quality'",
                "isort (>=5.5.4) ; extra == 'quality'",
                "pytest ; extra == 'tests'",
                "requests ; extra == 'tests'",
                "parameterized ; extra == 'tests'",
                "pytest-xdist ; extra == 'tests'",
                "Pillow ; extra == 'tests'"
            ],
            "requires_python": ">=3.7.0",
            "summary": "Optimum Library is an extension of the Hugging Face Transformers library, providing a framework to integrate third-party libraries from Hardware Partners and interface with their specific functionality.",
            "version": "1.5.0",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 16200391,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "b358e5449270ded490f270fcf6b8673d",
                    "sha256": "de642ec67cfa462f7acd7dfc8aa012e904ffff0ccfb6b5c2d0e9abf1e5a12665"
                },
                "downloads": -1,
                "filename": "optimum-1.5.0-py3-none-any.whl",
                "has_sig": false,
                "md5_digest": "b358e5449270ded490f270fcf6b8673d",
                "packagetype": "bdist_wheel",
                "python_version": "py3",
                "requires_python": ">=3.7.0",
                "size": 187244,
                "upload_time": "2022-11-17T16:40:58",
                "upload_time_iso_8601": "2022-11-17T16:40:58.845674Z",
                "url": "https://files.pythonhosted.org/packages/39/65/c7e4b18f9afe055023d41ec121d4ac26097883876744a22e15dd35686daf/optimum-1.5.0-py3-none-any.whl",
                "yanked": false,
                "yanked_reason": null
            },
            {
                "comment_text": "",
                "digests": {
                    "md5": "20ab4dd175f429aa63252935896ec605",
                    "sha256": "5b660fa64c33e44e7d9e3f670a9c7b04889f679ea780a7a6368079f847db5919"
                },
                "downloads": -1,
                "filename": "optimum-1.5.0.tar.gz",
                "has_sig": false,
                "md5_digest": "20ab4dd175f429aa63252935896ec605",
                "packagetype": "sdist",
                "python_version": "source",
                "requires_python": ">=3.7.0",
                "size": 150643,
                "upload_time": "2022-11-17T16:41:00",
                "upload_time_iso_8601": "2022-11-17T16:41:00.901101Z",
                "url": "https://files.pythonhosted.org/packages/5a/85/e0dda0c5b433f0fe23a8301b3b9397fa10dd54608e90c74a5cfddcaf361d/optimum-1.5.0.tar.gz",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "1.5.1": {
        "info": {
            "author": "HuggingFace Inc. Special Ops Team",
            "author_email": "hardware@huggingface.co",
            "bugtrack_url": null,
            "classifiers": [
                "Development Status :: 5 - Production/Stable",
                "Intended Audience :: Developers",
                "Intended Audience :: Education",
                "Intended Audience :: Science/Research",
                "License :: OSI Approved :: Apache Software License",
                "Operating System :: OS Independent",
                "Programming Language :: Python :: 3.7",
                "Programming Language :: Python :: 3.8",
                "Programming Language :: Python :: 3.9",
                "Topic :: Scientific/Engineering :: Artificial Intelligence"
            ],
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/huggingface/optimum",
            "keywords": "transformers,quantization,pruning,optimization,training,inference,onnx,onnx runtime,intel,habana,graphcore,neural compressor,ipu,hpu",
            "license": "Apache",
            "maintainer": "",
            "maintainer_email": "",
            "name": "optimum",
            "package_url": "https://pypi.org/project/optimum/",
            "platform": null,
            "project_url": "https://pypi.org/project/optimum/",
            "project_urls": {
                "Homepage": "https://github.com/huggingface/optimum"
            },
            "release_url": "https://pypi.org/project/optimum/1.5.1/",
            "requires_dist": [
                "coloredlogs",
                "sympy",
                "transformers[sentencepiece] (>=4.20.1)",
                "torch (>=1.9)",
                "packaging",
                "numpy",
                "huggingface-hub (>=0.8.0)",
                "optuna ; extra == 'benchmark'",
                "tqdm ; extra == 'benchmark'",
                "sklearn ; extra == 'benchmark'",
                "seqeval ; extra == 'benchmark'",
                "torchvision ; extra == 'benchmark'",
                "evaluate (>=0.2.0) ; extra == 'benchmark'",
                "pytest ; extra == 'dev'",
                "requests ; extra == 'dev'",
                "parameterized ; extra == 'dev'",
                "pytest-xdist ; extra == 'dev'",
                "Pillow ; extra == 'dev'",
                "black (~=22.0) ; extra == 'dev'",
                "flake8 (>=3.8.3) ; extra == 'dev'",
                "isort (>=5.5.4) ; extra == 'dev'",
                "onnx ; extra == 'exporters'",
                "onnxruntime ; extra == 'exporters'",
                "timm ; extra == 'exporters'",
                "tensorflow ; extra == 'exporters-tf'",
                "tf2onnx ; extra == 'exporters-tf'",
                "onnx ; extra == 'exporters-tf'",
                "onnxruntime ; extra == 'exporters-tf'",
                "timm ; extra == 'exporters-tf'",
                "optimum-graphcore ; extra == 'graphcore'",
                "optimum-habana ; extra == 'habana'",
                "optimum-intel ; extra == 'intel'",
                "optimum-intel[neural-compressor] ; extra == 'neural-compressor'",
                "optimum-intel[nncf] ; extra == 'nncf'",
                "onnx ; extra == 'onnxruntime'",
                "onnxruntime (>=1.9.0) ; extra == 'onnxruntime'",
                "datasets (>=1.2.1) ; extra == 'onnxruntime'",
                "evaluate ; extra == 'onnxruntime'",
                "protobuf (==3.20.1) ; extra == 'onnxruntime'",
                "onnx ; extra == 'onnxruntime-gpu'",
                "onnxruntime-gpu (>=1.9.0) ; extra == 'onnxruntime-gpu'",
                "datasets (>=1.2.1) ; extra == 'onnxruntime-gpu'",
                "evaluate ; extra == 'onnxruntime-gpu'",
                "protobuf (==3.20.1) ; extra == 'onnxruntime-gpu'",
                "optimum-intel[openvino] ; extra == 'openvino'",
                "black (~=22.0) ; extra == 'quality'",
                "flake8 (>=3.8.3) ; extra == 'quality'",
                "isort (>=5.5.4) ; extra == 'quality'",
                "pytest ; extra == 'tests'",
                "requests ; extra == 'tests'",
                "parameterized ; extra == 'tests'",
                "pytest-xdist ; extra == 'tests'",
                "Pillow ; extra == 'tests'"
            ],
            "requires_python": ">=3.7.0",
            "summary": "Optimum Library is an extension of the Hugging Face Transformers library, providing a framework to integrate third-party libraries from Hardware Partners and interface with their specific functionality.",
            "version": "1.5.1",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 16200391,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "7146073d667077ed12e536656006b22e",
                    "sha256": "bdde13620f35f6b133677576fa4496f94fdff0e4ba4f450717cb4b3b0a570651"
                },
                "downloads": -1,
                "filename": "optimum-1.5.1-py3-none-any.whl",
                "has_sig": false,
                "md5_digest": "7146073d667077ed12e536656006b22e",
                "packagetype": "bdist_wheel",
                "python_version": "py3",
                "requires_python": ">=3.7.0",
                "size": 187335,
                "upload_time": "2022-11-24T14:33:31",
                "upload_time_iso_8601": "2022-11-24T14:33:31.709377Z",
                "url": "https://files.pythonhosted.org/packages/99/13/d9171284c79243b6dc6cd79acef3a7aa57308cebe176f7627a9cafa33bcb/optimum-1.5.1-py3-none-any.whl",
                "yanked": false,
                "yanked_reason": null
            },
            {
                "comment_text": "",
                "digests": {
                    "md5": "f64448226bd2c9a6199236784df69f71",
                    "sha256": "b05f5d7003312bd520350557f8226f2c6b7119701de0ecaecf46cdf1a0d034ef"
                },
                "downloads": -1,
                "filename": "optimum-1.5.1.tar.gz",
                "has_sig": false,
                "md5_digest": "f64448226bd2c9a6199236784df69f71",
                "packagetype": "sdist",
                "python_version": "source",
                "requires_python": ">=3.7.0",
                "size": 151180,
                "upload_time": "2022-11-24T14:33:34",
                "upload_time_iso_8601": "2022-11-24T14:33:34.415027Z",
                "url": "https://files.pythonhosted.org/packages/20/3c/7a7421f96e6fe72547c6f7a3faf68d7c5e10d53316b1d8a0a9ce0f4cfbd6/optimum-1.5.1.tar.gz",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "1.5.2": {
        "info": {
            "author": "HuggingFace Inc. Special Ops Team",
            "author_email": "hardware@huggingface.co",
            "bugtrack_url": null,
            "classifiers": [
                "Development Status :: 5 - Production/Stable",
                "Intended Audience :: Developers",
                "Intended Audience :: Education",
                "Intended Audience :: Science/Research",
                "License :: OSI Approved :: Apache Software License",
                "Operating System :: OS Independent",
                "Programming Language :: Python :: 3.7",
                "Programming Language :: Python :: 3.8",
                "Programming Language :: Python :: 3.9",
                "Topic :: Scientific/Engineering :: Artificial Intelligence"
            ],
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/huggingface/optimum",
            "keywords": "transformers,quantization,pruning,optimization,training,inference,onnx,onnx runtime,intel,habana,graphcore,neural compressor,ipu,hpu",
            "license": "Apache",
            "maintainer": "",
            "maintainer_email": "",
            "name": "optimum",
            "package_url": "https://pypi.org/project/optimum/",
            "platform": null,
            "project_url": "https://pypi.org/project/optimum/",
            "project_urls": {
                "Homepage": "https://github.com/huggingface/optimum"
            },
            "release_url": "https://pypi.org/project/optimum/1.5.2/",
            "requires_dist": [
                "coloredlogs",
                "sympy",
                "transformers[sentencepiece] (>=4.20.1)",
                "torch (>=1.9)",
                "packaging",
                "numpy (<1.24.0)",
                "huggingface-hub (>=0.8.0)",
                "optuna ; extra == 'benchmark'",
                "tqdm ; extra == 'benchmark'",
                "sklearn ; extra == 'benchmark'",
                "seqeval ; extra == 'benchmark'",
                "torchvision ; extra == 'benchmark'",
                "evaluate (>=0.2.0) ; extra == 'benchmark'",
                "pytest ; extra == 'dev'",
                "requests ; extra == 'dev'",
                "parameterized ; extra == 'dev'",
                "pytest-xdist ; extra == 'dev'",
                "Pillow ; extra == 'dev'",
                "black (~=22.0) ; extra == 'dev'",
                "flake8 (>=3.8.3) ; extra == 'dev'",
                "isort (>=5.5.4) ; extra == 'dev'",
                "onnx ; extra == 'exporters'",
                "onnxruntime ; extra == 'exporters'",
                "timm ; extra == 'exporters'",
                "tensorflow ; extra == 'exporters-tf'",
                "tf2onnx ; extra == 'exporters-tf'",
                "onnx ; extra == 'exporters-tf'",
                "onnxruntime ; extra == 'exporters-tf'",
                "timm ; extra == 'exporters-tf'",
                "optimum-graphcore ; extra == 'graphcore'",
                "optimum-habana ; extra == 'habana'",
                "optimum-intel ; extra == 'intel'",
                "optimum-intel[neural-compressor] ; extra == 'neural-compressor'",
                "optimum-intel[nncf] ; extra == 'nncf'",
                "onnx ; extra == 'onnxruntime'",
                "onnxruntime (>=1.9.0) ; extra == 'onnxruntime'",
                "datasets (>=1.2.1) ; extra == 'onnxruntime'",
                "evaluate ; extra == 'onnxruntime'",
                "protobuf (==3.20.1) ; extra == 'onnxruntime'",
                "onnx ; extra == 'onnxruntime-gpu'",
                "onnxruntime-gpu (>=1.9.0) ; extra == 'onnxruntime-gpu'",
                "datasets (>=1.2.1) ; extra == 'onnxruntime-gpu'",
                "evaluate ; extra == 'onnxruntime-gpu'",
                "protobuf (==3.20.1) ; extra == 'onnxruntime-gpu'",
                "optimum-intel[openvino] ; extra == 'openvino'",
                "black (~=22.0) ; extra == 'quality'",
                "flake8 (>=3.8.3) ; extra == 'quality'",
                "isort (>=5.5.4) ; extra == 'quality'",
                "pytest ; extra == 'tests'",
                "requests ; extra == 'tests'",
                "parameterized ; extra == 'tests'",
                "pytest-xdist ; extra == 'tests'",
                "Pillow ; extra == 'tests'"
            ],
            "requires_python": ">=3.7.0",
            "summary": "Optimum Library is an extension of the Hugging Face Transformers library, providing a framework to integrate third-party libraries from Hardware Partners and interface with their specific functionality.",
            "version": "1.5.2",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 16200391,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "2fddff040bcad2cdf59e21eaa3303f81",
                    "sha256": "6f94da3acd9be7216b6665046684d1d6b798ed9b6d393068f389c65ce3fe1820"
                },
                "downloads": -1,
                "filename": "optimum-1.5.2-py3-none-any.whl",
                "has_sig": false,
                "md5_digest": "2fddff040bcad2cdf59e21eaa3303f81",
                "packagetype": "bdist_wheel",
                "python_version": "py3",
                "requires_python": ">=3.7.0",
                "size": 187956,
                "upload_time": "2022-12-19T16:22:33",
                "upload_time_iso_8601": "2022-12-19T16:22:33.427319Z",
                "url": "https://files.pythonhosted.org/packages/f8/28/30bcfb8d17162b36b86fe55cff34f0d4105c52036155ab72d00e3f7fbfba/optimum-1.5.2-py3-none-any.whl",
                "yanked": false,
                "yanked_reason": null
            },
            {
                "comment_text": "",
                "digests": {
                    "md5": "1b1f8d4f7f66f9d82ca09406bf452d7e",
                    "sha256": "2b94d8353aef243293cff2f121082854ff3c8570ac0796cef3894207384d9555"
                },
                "downloads": -1,
                "filename": "optimum-1.5.2.tar.gz",
                "has_sig": false,
                "md5_digest": "1b1f8d4f7f66f9d82ca09406bf452d7e",
                "packagetype": "sdist",
                "python_version": "source",
                "requires_python": ">=3.7.0",
                "size": 151309,
                "upload_time": "2022-12-19T16:22:35",
                "upload_time_iso_8601": "2022-12-19T16:22:35.714053Z",
                "url": "https://files.pythonhosted.org/packages/e5/40/51e6bb933ec5f9812d4d14c0c460ca0c6201491bdd46c778c7e2a18172e8/optimum-1.5.2.tar.gz",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "1.6.0": {
        "info": {
            "author": "HuggingFace Inc. Special Ops Team",
            "author_email": "hardware@huggingface.co",
            "bugtrack_url": null,
            "classifiers": [
                "Development Status :: 5 - Production/Stable",
                "Intended Audience :: Developers",
                "Intended Audience :: Education",
                "Intended Audience :: Science/Research",
                "License :: OSI Approved :: Apache Software License",
                "Operating System :: OS Independent",
                "Programming Language :: Python :: 3.7",
                "Programming Language :: Python :: 3.8",
                "Programming Language :: Python :: 3.9",
                "Topic :: Scientific/Engineering :: Artificial Intelligence"
            ],
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/huggingface/optimum",
            "keywords": "transformers,quantization,pruning,optimization,training,inference,onnx,onnx runtime,intel,habana,graphcore,neural compressor,ipu,hpu",
            "license": "Apache",
            "maintainer": "",
            "maintainer_email": "",
            "name": "optimum",
            "package_url": "https://pypi.org/project/optimum/",
            "platform": null,
            "project_url": "https://pypi.org/project/optimum/",
            "project_urls": {
                "Homepage": "https://github.com/huggingface/optimum"
            },
            "release_url": "https://pypi.org/project/optimum/1.6.0/",
            "requires_dist": [
                "coloredlogs",
                "sympy",
                "transformers[sentencepiece] (>=4.20.1)",
                "torch (>=1.9)",
                "packaging",
                "numpy (<1.24.0)",
                "huggingface-hub (>=0.8.0)",
                "optuna ; extra == 'benchmark'",
                "tqdm ; extra == 'benchmark'",
                "scikit-learn ; extra == 'benchmark'",
                "seqeval ; extra == 'benchmark'",
                "torchvision ; extra == 'benchmark'",
                "evaluate (>=0.2.0) ; extra == 'benchmark'",
                "pytest ; extra == 'dev'",
                "requests ; extra == 'dev'",
                "parameterized ; extra == 'dev'",
                "pytest-xdist ; extra == 'dev'",
                "Pillow ; extra == 'dev'",
                "sacremoses ; extra == 'dev'",
                "diffusers ; extra == 'dev'",
                "black (~=22.0) ; extra == 'dev'",
                "flake8 (>=3.8.3) ; extra == 'dev'",
                "isort (>=5.5.4) ; extra == 'dev'",
                "onnx ; extra == 'exporters'",
                "onnxruntime ; extra == 'exporters'",
                "timm ; extra == 'exporters'",
                "tensorflow (<2.11,>=2.4) ; extra == 'exporters-tf'",
                "tf2onnx ; extra == 'exporters-tf'",
                "onnx ; extra == 'exporters-tf'",
                "onnxruntime ; extra == 'exporters-tf'",
                "timm ; extra == 'exporters-tf'",
                "optimum-graphcore ; extra == 'graphcore'",
                "optimum-habana ; extra == 'habana'",
                "optimum-intel ; extra == 'intel'",
                "optimum-intel[neural-compressor] ; extra == 'neural-compressor'",
                "optimum-intel[nncf] ; extra == 'nncf'",
                "onnx ; extra == 'onnxruntime'",
                "onnxruntime (>=1.9.0) ; extra == 'onnxruntime'",
                "datasets (>=1.2.1) ; extra == 'onnxruntime'",
                "evaluate ; extra == 'onnxruntime'",
                "protobuf (==3.20.1) ; extra == 'onnxruntime'",
                "onnx ; extra == 'onnxruntime-gpu'",
                "onnxruntime-gpu (>=1.9.0) ; extra == 'onnxruntime-gpu'",
                "datasets (>=1.2.1) ; extra == 'onnxruntime-gpu'",
                "evaluate ; extra == 'onnxruntime-gpu'",
                "protobuf (==3.20.1) ; extra == 'onnxruntime-gpu'",
                "optimum-intel[openvino] ; extra == 'openvino'",
                "black (~=22.0) ; extra == 'quality'",
                "flake8 (>=3.8.3) ; extra == 'quality'",
                "isort (>=5.5.4) ; extra == 'quality'",
                "pytest ; extra == 'tests'",
                "requests ; extra == 'tests'",
                "parameterized ; extra == 'tests'",
                "pytest-xdist ; extra == 'tests'",
                "Pillow ; extra == 'tests'",
                "sacremoses ; extra == 'tests'",
                "diffusers ; extra == 'tests'"
            ],
            "requires_python": ">=3.7.0",
            "summary": "Optimum Library is an extension of the Hugging Face Transformers library, providing a framework to integrate third-party libraries from Hardware Partners and interface with their specific functionality.",
            "version": "1.6.0",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 16200391,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "7a6bfdfa6830990540d8482c5f13be21",
                    "sha256": "9dcd04aa16f519ff2846be0d5be6ac4eb142bbd5b063e13d5c630846dd178fa4"
                },
                "downloads": -1,
                "filename": "optimum-1.6.0-py3-none-any.whl",
                "has_sig": false,
                "md5_digest": "7a6bfdfa6830990540d8482c5f13be21",
                "packagetype": "bdist_wheel",
                "python_version": "py3",
                "requires_python": ">=3.7.0",
                "size": 219404,
                "upload_time": "2022-12-23T15:27:44",
                "upload_time_iso_8601": "2022-12-23T15:27:44.292437Z",
                "url": "https://files.pythonhosted.org/packages/d1/f9/41a5d1988ac0c1ed613ffb3c0b3703fafcf40b1c487d4a25dce63cae3665/optimum-1.6.0-py3-none-any.whl",
                "yanked": false,
                "yanked_reason": null
            },
            {
                "comment_text": "",
                "digests": {
                    "md5": "3426580c1f649bbac7d475ea33097bdd",
                    "sha256": "00f9861a914856a605e879f133bf3d76ddd5d7c33329c6271fadf338b4c6ec03"
                },
                "downloads": -1,
                "filename": "optimum-1.6.0.tar.gz",
                "has_sig": false,
                "md5_digest": "3426580c1f649bbac7d475ea33097bdd",
                "packagetype": "sdist",
                "python_version": "source",
                "requires_python": ">=3.7.0",
                "size": 176599,
                "upload_time": "2022-12-23T15:27:48",
                "upload_time_iso_8601": "2022-12-23T15:27:48.077952Z",
                "url": "https://files.pythonhosted.org/packages/ee/54/95e48beceea4321ca1ec8ba9d09f1ffc8263194994aa9e2eb13ded2c0c38/optimum-1.6.0.tar.gz",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "1.6.1": {
        "info": {
            "author": "HuggingFace Inc. Special Ops Team",
            "author_email": "hardware@huggingface.co",
            "bugtrack_url": null,
            "classifiers": [
                "Development Status :: 5 - Production/Stable",
                "Intended Audience :: Developers",
                "Intended Audience :: Education",
                "Intended Audience :: Science/Research",
                "License :: OSI Approved :: Apache Software License",
                "Operating System :: OS Independent",
                "Programming Language :: Python :: 3.7",
                "Programming Language :: Python :: 3.8",
                "Programming Language :: Python :: 3.9",
                "Topic :: Scientific/Engineering :: Artificial Intelligence"
            ],
            "description": "[![ONNX Runtime](https://github.com/huggingface/optimum/actions/workflows/test_onnxruntime.yml/badge.svg)](https://github.com/huggingface/optimum/actions/workflows/test_onnxruntime.yml)\n\n# Hugging Face Optimum\n\n\ud83e\udd17 Optimum is an extension of \ud83e\udd17 Transformers, providing a set of optimization tools enabling maximum efficiency to train and run models on targeted hardware.\n\nThe AI ecosystem evolves quickly and more and more specialized hardware along with their own optimizations are emerging every day.\nAs such, Optimum enables users to efficiently use any of these platforms with the same ease inherent to transformers.\n\n\n## Integration with Hardware Partners\n\nOptimum aims at providing more diversity towards the kind of hardware users can target to train and finetune their models.\n\nTo achieve this, we are collaborating with the following hardware manufacturers in order to provide the best transformers integration:\n- [Graphcore IPUs](https://github.com/huggingface/optimum-graphcore) - IPUs are a completely new kind of massively parallel processor to accelerate machine intelligence. More information [here](https://www.graphcore.ai/products/ipu).\n- [Habana Gaudi Processor (HPU)](https://github.com/huggingface/optimum-habana) - [HPUs](https://docs.habana.ai/en/latest/Gaudi_Overview/Gaudi_Architecture.html) are designed to maximize training throughput and efficiency. More information [here](https://habana.ai/training/).\n- [Intel](https://github.com/huggingface/optimum-intel) - Enabling the usage of Intel tools to accelerate inference on Intel architectures. More information about [Neural Compressor](https://www.intel.com/content/www/us/en/developer/tools/oneapi/neural-compressor.html) and [OpenVINO](https://docs.openvino.ai/latest/index.html).\n- More to come soon! :star:\n\n\n## Installation\n\n\ud83e\udd17 Optimum can be installed using `pip` as follows:\n\n```bash\npython -m pip install optimum\n```\n\nIf you'd like to use the accelerator-specific features of \ud83e\udd17 Optimum, you can install the required dependencies according to the table below:\n\n| Accelerator                                                                                                            | Installation                                      |\n|:-----------------------------------------------------------------------------------------------------------------------|:--------------------------------------------------|\n| [ONNX Runtime](https://onnxruntime.ai/docs/)                                                                           | `python -m pip install optimum[onnxruntime]`      |\n| [Intel Neural Compressor](https://www.intel.com/content/www/us/en/developer/tools/oneapi/neural-compressor.html)       | `python -m pip install optimum[neural-compressor]`|\n| [OpenVINO](https://docs.openvino.ai/latest/index.html)                                                                 | `python -m pip install optimum[openvino,nncf]`    |\n| [Graphcore IPU](https://www.graphcore.ai/products/ipu)                                                                 | `python -m pip install optimum[graphcore]`        |\n| [Habana Gaudi Processor (HPU)](https://habana.ai/training/)                                                            | `python -m pip install optimum[habana]`           |\n\n\nIf you'd like to play with the examples or need the bleeding edge of the code and can't wait for a new release, you can install the base library from source as follows:\n\n```bash\npython -m pip install git+https://github.com/huggingface/optimum.git\n```\n\nFor the accelerator-specific features, you can install them by appending `#egg=optimum[accelerator_type]` to the `pip` command, e.g.\n\n```bash\npython -m pip install git+https://github.com/huggingface/optimum.git#egg=optimum[onnxruntime]\n```\n\n\n## Optimizing models towards inference\n\nAlong with supporting dedicated AI hardware for training, Optimum also provides inference optimizations towards various frameworks and\nplatforms.\n\nOptimum enables the usage of popular compression techniques such as quantization and pruning by supporting [ONNX Runtime](https://onnxruntime.ai/docs/) along with Intel [Neural Compressor](https://www.intel.com/content/www/us/en/developer/tools/oneapi/neural-compressor.html) and OpenVINO [NNCF](https://docs.openvino.ai/latest/tmo_introduction.html).\n\n| Features                           | ONNX Runtime          |     Neural Compressor   |         OpenVINO        |\n|:----------------------------------:|:---------------------:|:-----------------------:|:-----------------------:|\n| Post-training Dynamic Quantization |  :heavy_check_mark:   |    :heavy_check_mark:   |    :heavy_check_mark:   |\n| Post-training Static Quantization  |  :heavy_check_mark:   |    :heavy_check_mark:   |    :heavy_check_mark:   |\n| Quantization Aware Training (QAT)  |  Stay tuned! :star:   |    :heavy_check_mark:   |           N/A           |\n| Pruning                            |        N/A            |    :heavy_check_mark:   |    Stay tuned! :star:   |\n\n## Quick tour\n\nCheck out the examples below to see how \ud83e\udd17 Optimum can be used to train and run inference on various hardware accelerators.\n\n## Accelerated inference\n\n#### ONNX Runtime\n\nTo accelerate inference with ONNX Runtime, \ud83e\udd17 Optimum uses _configuration objects_ to define parameters for graph optimization and quantization. These objects are then used to instantiate dedicated _optimizers_ and _quantizers_.\n\nBefore applying quantization or optimization, first we need to load our model. To load a model and run inference with ONNX Runtime, you can just replace the canonical Transformers [`AutoModelForXxx`](https://huggingface.co/docs/transformers/model_doc/auto#transformers.AutoModel) class with the corresponding [`ORTModelForXxx`](https://huggingface.co/docs/optimum/onnxruntime/package_reference/modeling_ort#optimum.onnxruntime.ORTModel) class. If you want to load from a PyTorch checkpoint, set `from_transformers=True` to export your model to the ONNX format.\n\n```python\nfrom optimum.onnxruntime import ORTModelForSequenceClassification\nfrom transformers import AutoTokenizer\n\nmodel_checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\nsave_directory = \"tmp/onnx/\"\n# Load a model from transformers and export it to ONNX\ntokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\nort_model = ORTModelForSequenceClassification.from_pretrained(model_checkpoint, from_transformers=True)\n# Save the ONNX model and tokenizer\nort_model.save_pretrained(save_directory)\ntokenizer.save_pretrained(save_directory)\n```\n\nLet's see now how we can apply dynamic quantization with ONNX Runtime:\n\n```python\nfrom optimum.onnxruntime.configuration import AutoQuantizationConfig\nfrom optimum.onnxruntime import ORTQuantizer\n\n# Define the quantization methodology\nqconfig = AutoQuantizationConfig.arm64(is_static=False, per_channel=False)\nquantizer = ORTQuantizer.from_pretrained(ort_model)\n# Apply dynamic quantization on the model\nquantizer.quantize(save_dir=save_directory, quantization_config=qconfig)\n```\n\nIn this example, we've quantized a model from the Hugging Face Hub, in the same manner we can quantize a model hosted locally by providing the path to the directory containing the model weights. The result from applying the `quantize()` method is a `model_quantized.onnx` file that can be used to run inference. Here's an example of how to load an ONNX Runtime model and generate predictions with it:\n\n```python\nfrom optimum.onnxruntime import ORTModelForSequenceClassification\nfrom transformers import pipeline, AutoTokenizer\n\nmodel = ORTModelForSequenceClassification.from_pretrained(save_directory, file_name=\"model_quantized.onnx\")\ntokenizer = AutoTokenizer.from_pretrained(save_directory)\nclassifier = pipeline(\"text-classification\", model=model, tokenizer=tokenizer)\nresults = classifier(\"I love burritos!\")\n```\n\nYou can find more examples in the [documentation](https://huggingface.co/docs/optimum/onnxruntime/quickstart) and in the [examples](https://github.com/huggingface/optimum/tree/main/examples/onnxruntime).\n\n\n#### Intel\n\nTo load a model and run inference with OpenVINO Runtime, you can just replace your `AutoModelForXxx` class with the corresponding `OVModelForXxx` class.\nIf you want to load a PyTorch checkpoint, set `from_transformers=True` to convert your model to the OpenVINO IR (Intermediate Representation).\n\n```diff\n- from transformers import AutoModelForSequenceClassification\n+ from optimum.intel.openvino import OVModelForSequenceClassification\n  from transformers import AutoTokenizer, pipeline\n\n  # Download a tokenizer and model from the Hub and convert to OpenVINO format\n  tokenizer = AutoTokenizer.from_pretrained(model_id)\n  model_id = \"distilbert-base-uncased-finetuned-sst-2-english\"\n- model = AutoModelForSequenceClassification.from_pretrained(model_id)\n+ model = OVModelForSequenceClassification.from_pretrained(model_id, from_transformers=True)\n\n  # Run inference!\n  classifier = pipeline(\"text-classification\", model=model, tokenizer=tokenizer)\n  results = classifier(\"He's a dreadful magician.\")\n```\n\nYou can find more examples in the [documentation](https://huggingface.co/docs/optimum/intel/inference) and in the [examples](https://github.com/huggingface/optimum-intel/tree/main/examples/openvino).\n\n\n## Accelerated training\n\n#### Habana\n\nTo train transformers on Habana's Gaudi processors, \ud83e\udd17 Optimum provides a `GaudiTrainer` that is very similar to the \ud83e\udd17 Transformers [Trainer](https://huggingface.co/docs/transformers/main_classes/trainer). Here is a simple example:\n\n```diff\n- from transformers import Trainer, TrainingArguments\n+ from optimum.habana import GaudiTrainer, GaudiTrainingArguments\n\n  # Download a pretrained model from the Hub\n  model = AutoModelForXxx.from_pretrained(\"bert-base-uncased\")\n\n  # Define the training arguments\n- training_args = TrainingArguments(\n+ training_args = GaudiTrainingArguments(\n      output_dir=\"path/to/save/folder/\",\n+     use_habana=True,\n+     use_lazy_mode=True,\n+     gaudi_config_name=\"Habana/bert-base-uncased\",\n      ...\n  )\n\n  # Initialize the trainer\n- trainer = Trainer(\n+ trainer = GaudiTrainer(\n      model=model,\n      args=training_args,\n      train_dataset=train_dataset,\n      ...\n  )\n\n  # Use Habana Gaudi processor for training!\n  trainer.train()\n```\n\nYou can find more examples in the [documentation](https://huggingface.co/docs/optimum/habana/quickstart) and in the [examples](https://github.com/huggingface/optimum-habana/tree/main/examples).\n\n\n#### Graphcore\n\nTo train transformers on Graphcore's IPUs, \ud83e\udd17 Optimum provides a `IPUTrainer` that is very similar to the \ud83e\udd17 Transformers [Trainer](https://huggingface.co/docs/transformers/main_classes/trainer). Here is a simple example:\n\n```diff\n- from transformers import Trainer, TrainingArguments\n+ from optimum.graphcore import IPUConfig, IPUTrainer, IPUTrainingArguments\n\n  # Download a pretrained model from the Hub\n  model = AutoModelForXxx.from_pretrained(\"bert-base-uncased\")\n\n  # Define the training arguments\n- training_args = TrainingArguments(\n+ training_args = IPUTrainingArguments(\n      output_dir=\"path/to/save/folder/\",\n+     ipu_config_name=\"Graphcore/bert-base-ipu\", # Any IPUConfig on the Hub or stored locally\n      ...\n  )\n\n  # Define the configuration to compile and put the model on the IPU\n+ ipu_config = IPUConfig.from_pretrained(training_args.ipu_config_name)\n\n  # Initialize the trainer\n- trainer = Trainer(\n+ trainer = IPUTrainer(\n      model=model,\n+     ipu_config=ipu_config\n      args=training_args,\n      train_dataset=train_dataset\n      ...\n  )\n\n  # Use Graphcore IPU for training!\n  trainer.train()\n```\n\nYou can find more examples in the [documentation](https://huggingface.co/docs/optimum/graphcore/quickstart) and in the [examples](https://github.com/huggingface/optimum-graphcore/tree/main/examples).\n\n\n#### ONNX Runtime\n\nTo train transformers with ONNX Runtime's acceleration features, \ud83e\udd17 Optimum provides a `ORTTrainer` that is very similar to the \ud83e\udd17 Transformers [Trainer](https://huggingface.co/docs/transformers/main_classes/trainer). Here is a simple example:\n\n```diff\n- from transformers import Trainer, TrainingArguments\n+ from optimum.onnxruntime import ORTTrainer, ORTTrainingArguments\n\n  # Download a pretrained model from the Hub\n  model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\")\n\n  # Define the training arguments\n- training_args = TrainingArguments(\n+ training_args = ORTTrainingArguments(\n      output_dir=\"path/to/save/folder/\",\n      optim=\"adamw_ort_fused\",\n      ...\n  )\n\n  # Create a ONNX Runtime Trainer\n- trainer = Trainer(\n+ trainer = ORTTrainer(\n      model=model,\n      args=training_args,\n      train_dataset=train_dataset,\n+     feature=\"sequence-classification\", # The model type to export to ONNX\n      ...\n  )\n\n  # Use ONNX Runtime for training!\n  trainer.train()\n```\n\nYou can find more examples in the [documentation](https://huggingface.co/docs/optimum/onnxruntime/usage_guides/trainer) and in the [examples](https://github.com/huggingface/optimum/tree/main/examples/onnxruntime/training).\n\n\n",
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/huggingface/optimum",
            "keywords": "transformers,quantization,pruning,optimization,training,inference,onnx,onnx runtime,intel,habana,graphcore,neural compressor,ipu,hpu",
            "license": "Apache",
            "maintainer": "",
            "maintainer_email": "",
            "name": "optimum",
            "package_url": "https://pypi.org/project/optimum/",
            "platform": null,
            "project_url": "https://pypi.org/project/optimum/",
            "project_urls": {
                "Homepage": "https://github.com/huggingface/optimum"
            },
            "release_url": "https://pypi.org/project/optimum/1.6.1/",
            "requires_dist": [
                "coloredlogs",
                "sympy",
                "transformers[sentencepiece] (>=4.20.1)",
                "torch (>=1.9)",
                "packaging",
                "numpy (<1.24.0)",
                "huggingface-hub (>=0.8.0)",
                "optuna ; extra == 'benchmark'",
                "tqdm ; extra == 'benchmark'",
                "scikit-learn ; extra == 'benchmark'",
                "seqeval ; extra == 'benchmark'",
                "torchvision ; extra == 'benchmark'",
                "evaluate (>=0.2.0) ; extra == 'benchmark'",
                "pytest ; extra == 'dev'",
                "requests ; extra == 'dev'",
                "parameterized ; extra == 'dev'",
                "pytest-xdist ; extra == 'dev'",
                "Pillow ; extra == 'dev'",
                "sacremoses ; extra == 'dev'",
                "diffusers ; extra == 'dev'",
                "black (~=22.0) ; extra == 'dev'",
                "flake8 (>=3.8.3) ; extra == 'dev'",
                "isort (>=5.5.4) ; extra == 'dev'",
                "onnx ; extra == 'exporters'",
                "onnxruntime ; extra == 'exporters'",
                "timm ; extra == 'exporters'",
                "tensorflow (<2.11,>=2.4) ; extra == 'exporters-tf'",
                "tf2onnx ; extra == 'exporters-tf'",
                "onnx ; extra == 'exporters-tf'",
                "onnxruntime ; extra == 'exporters-tf'",
                "timm ; extra == 'exporters-tf'",
                "optimum-graphcore ; extra == 'graphcore'",
                "optimum-habana ; extra == 'habana'",
                "optimum-intel ; extra == 'intel'",
                "optimum-intel[neural-compressor] ; extra == 'neural-compressor'",
                "optimum-intel[nncf] ; extra == 'nncf'",
                "onnx ; extra == 'onnxruntime'",
                "onnxruntime (>=1.9.0) ; extra == 'onnxruntime'",
                "datasets (>=1.2.1) ; extra == 'onnxruntime'",
                "evaluate ; extra == 'onnxruntime'",
                "protobuf (==3.20.1) ; extra == 'onnxruntime'",
                "onnx ; extra == 'onnxruntime-gpu'",
                "onnxruntime-gpu (>=1.9.0) ; extra == 'onnxruntime-gpu'",
                "datasets (>=1.2.1) ; extra == 'onnxruntime-gpu'",
                "evaluate ; extra == 'onnxruntime-gpu'",
                "protobuf (==3.20.1) ; extra == 'onnxruntime-gpu'",
                "optimum-intel[openvino] ; extra == 'openvino'",
                "black (~=22.0) ; extra == 'quality'",
                "flake8 (>=3.8.3) ; extra == 'quality'",
                "isort (>=5.5.4) ; extra == 'quality'",
                "pytest ; extra == 'tests'",
                "requests ; extra == 'tests'",
                "parameterized ; extra == 'tests'",
                "pytest-xdist ; extra == 'tests'",
                "Pillow ; extra == 'tests'",
                "sacremoses ; extra == 'tests'",
                "diffusers ; extra == 'tests'"
            ],
            "requires_python": ">=3.7.0",
            "summary": "Optimum Library is an extension of the Hugging Face Transformers library, providing a framework to integrate third-party libraries from Hardware Partners and interface with their specific functionality.",
            "version": "1.6.1",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 16200391,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "e4cb1c8a5db7296c3b47bebc08dd1690",
                    "sha256": "6231825fa18f1686954c8be5d5cbffbed1b2c6ccd2c4f6d50af3bc8f59e57165"
                },
                "downloads": -1,
                "filename": "optimum-1.6.1-py3-none-any.whl",
                "has_sig": false,
                "md5_digest": "e4cb1c8a5db7296c3b47bebc08dd1690",
                "packagetype": "bdist_wheel",
                "python_version": "py3",
                "requires_python": ">=3.7.0",
                "size": 222597,
                "upload_time": "2022-12-23T20:31:56",
                "upload_time_iso_8601": "2022-12-23T20:31:56.571239Z",
                "url": "https://files.pythonhosted.org/packages/f9/b2/8d4478cc0543bfb84209afc8b117ea6a044c2ef2d1fa1aa79ab8815a9c56/optimum-1.6.1-py3-none-any.whl",
                "yanked": false,
                "yanked_reason": null
            },
            {
                "comment_text": "",
                "digests": {
                    "md5": "98827c27c991cbeabc9e0594bb5f90e9",
                    "sha256": "57bc1a39296b4fc7bbd168a7cc4fdf2e4ea6a36ba54d25e73f61885c8c9abc27"
                },
                "downloads": -1,
                "filename": "optimum-1.6.1.tar.gz",
                "has_sig": false,
                "md5_digest": "98827c27c991cbeabc9e0594bb5f90e9",
                "packagetype": "sdist",
                "python_version": "source",
                "requires_python": ">=3.7.0",
                "size": 178519,
                "upload_time": "2022-12-23T20:32:00",
                "upload_time_iso_8601": "2022-12-23T20:32:00.597150Z",
                "url": "https://files.pythonhosted.org/packages/a1/f0/0533fd894a316c55f8c8791dbc8bb3a702e901b623b1b6ed0fb90f1009ac/optimum-1.6.1.tar.gz",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    }
}
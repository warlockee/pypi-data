{
    "0.1.0": {
        "info": {
            "author": "Mert Kurttutan",
            "author_email": "kurttutan.mert@gmail.com",
            "bugtrack_url": null,
            "classifiers": [
                "License :: OSI Approved :: MIT License",
                "Programming Language :: Python :: 3",
                "Programming Language :: Python :: 3.10",
                "Programming Language :: Python :: 3.11",
                "Programming Language :: Python :: 3.7",
                "Programming Language :: Python :: 3.8",
                "Programming Language :: Python :: 3.9"
            ],
            "description": "# torchview\n\n[![Python 3.7+](https://img.shields.io/badge/python-3.7+-blue.svg)](https://www.python.org/downloads/release/python-370/)\n[![PyPI version](https://badge.fury.io/py/torchview.svg)](https://badge.fury.io/py/torchview)\n[![Conda version](https://img.shields.io/conda/vn/conda-forge/torchview)](https://anaconda.org/conda-forge/torchview)\n[![Build Status](https://github.com/mert-kurttutan/torchview/actions/workflows/test.yml/badge.svg)](https://github.com/mert-kurttutan/torchview/actions/workflows/test.yml)\n[![GitHub license](https://img.shields.io/github/license/mert-kurttutan/torchview)](https://github.com/mert-kurttutan/torchview/blob/main/LICENSE)\n[![codecov](https://codecov.io/gh/mert-kurttutan/torchview/branch/main/graph/badge.svg)](https://codecov.io/gh/mert-kurttutan/torchview)\n[![Downloads](https://pepy.tech/badge/torchview)](https://pepy.tech/project/torchview)\n\n\n\nTorchview provides visualization of pytorch models in the form of visual graphs.\nSupports PyTorch versions 1.7.1+.\n\n# Installation\n\nFirst, you need to install graphviz, \n```\npip install graphviz\n```\nFor python interface of graphiz to work, you need to have dot layout command working in your system, see the details [here](https://graphviz.readthedocs.io/en/stable/manual.html)\n\nThen, continue with installing torchview\n```\npip install torchview\n```\n\nAlternatively, via conda:\n\n```\nconda install -c conda-forge torchview\n```\n\n# How To Use\n\n```python\nfrom torchview import draw_graph\n\nmodel = MLP()\nbatch_size = 16\nmodel_graph = draw_graph(model, input_size=(batch_size, 128))\nmodel_graph.visual_graph\n```\n\n\n<img src=\"https://raw.githubusercontent.com/mert-kurttutan/torchview/main/docs/images/mlp.png\" height=\"400\"/>\n\n<!-- single_input_all_cols.out -->\n\nNote: Output graphviz visuals return images with desired sizes. But sometimes, on VScode, some shapes are being cropped due to large size and svg rendering on by VSCode. To solve this, I suggest you run the following\n```python\nimport graphviz\ngraphviz.set_jupyter_format('png')\n```\nThis problem does not occur on other jupyter platforms e.g. JupyterLab or Google Colab.\n\n**Supported Features**\n* Almost all the models, RNN, Sequentials, Skip Connection\n* Shows operations between tensors (in addition to module calls)\n* Rolling/Unrolling feature. Recursively used modules can be rolled visually, see below.\n\n# Documentation\n\n```python\ndef draw_graph(\n    model: nn.Module,\n    input_data: INPUT_DATA_TYPE | None = None,\n    input_size: INPUT_SIZE_TYPE | None = None,\n    graph_name: str = 'model',\n    depth: int | float = 3,\n    device: torch.device | str | None = None,\n    dtypes: list[torch.dtype] | None = None,\n    mode: str | None = None,\n    strict: bool = True,\n    hide_module_functions: bool = True,\n    hide_inner_tensors: bool = True,\n    roll: bool = False,\n    show_shapes: bool = True,\n    save_graph: bool = False,\n    filename: str | None = None,\n    directory: str = '.',\n    **kwargs: Any,\n) -> ComputationGraph:\n    '''Returns visual representation of the input Pytorch Module with\n    ComputationGraph object. ComputationGraph object contains:\n\n    1) Root nodes (usually tensor node for input tensors) which connect to all\n    the other nodes of computation graph of pytorch module recorded during forward\n    propagation.\n\n    2) graphviz.Digraph object that contains visual representation of computation\n    graph of pytorch module. This graph visual shows modules/ module hierarchy,\n    torch_functions, shapes and tensors recorded during forward prop, for examples\n    see documentation, and colab notebooks.\n\n\n    Args:\n        model (nn.Module):\n            Pytorch model to represent visually.\n\n        input_data (data structure containing torch.Tensor):\n            input for forward method of model. Wrap it in a list for\n            multiple args or in a dict or kwargs\n\n        input_size (Sequence of Sizes):\n            Shape of input data as a List/Tuple/torch.Size\n            (dtypes must match model input, default is FloatTensors).\n            Default: None\n\n        graph_name (str):\n            Name for graphviz.Digraph object. Also default name graphviz file\n            of Graph Visualization\n            Default: 'model'\n\n        depth (int):\n            Upper limit for depth of nodes to be shown in visualization.\n            Depth is measured how far is module/tensor inside the module hierarchy.\n            For instance, main module has depth=0, whereas submodule of main module\n            has depth=1, and so on.\n            Default: 3\n\n        device (str or torch.device):\n            Device to place and input tensors. Defaults to\n            gpu if cuda is seen by pytorch, otherwise to cpu.\n            Default: None\n\n        dtypes (list of torch.dtype):\n            Uses dtypes to set the types of input tensor if\n            input size is given.\n\n        mode (str):\n            Mode of model to use for forward prop. Defaults\n            to Eval mode if not given\n            Default: None\n\n        strict (bool):\n            if true, graphviz visual does not allow multiple edges\n            between nodes. Mutiple edge occurs e.g. when there are tensors\n            from module node to module node and hiding those tensors\n            Default: True\n\n        hide_module_function (bool):\n            Determines whether to hide module torch_functions. Some\n            modules consist only of torch_functions (no submodule),\n            e.g. nn.Conv2d.\n            True => Dont include module functions in graphviz\n            False => Include modules function in graphviz\n            Default: True\n\n        hide_inner_tensors (bool):\n            Inner tensor is all the tensors of computation graph\n            but input and output tensors\n            True => Does not show inner tensors in graphviz\n            False => Shows inner tensors in graphviz\n            Default: True\n\n        roll (bool):\n            If true, rolls recursive modules.\n            Default: False\n\n        show_shapes (bool):\n            True => Show shape of tensor, input, and output\n            False => Dont show\n            Default: True\n\n        save_graph (bool):\n            True => Saves output file of graphviz graph\n            False => Does not save\n            Default: False\n\n        filename (str):\n            name of the file to store dot syntax representation and\n            image file of graphviz graph. Defaults to graph_name\n\n        directory (str):\n            directory in which to store graphviz output files.\n            Default: .\n\n    Returns:\n        ComputationGraph object that contains visualization of the input\n        pytorch model in the form of graphviz Digraph object\n    '''\n```\n\n# Examples\n\n## Rolled Version of Recursive Networks\n\n```python\nfrom torchview import draw_graph\n\nmodel_graph = draw_graph(\n    SimpleRNN(), input_size=(2, 3),\n    graph_name='RecursiveNet',\n    roll=True\n)\nmodel_graph.visual_graph\n```\n\n<img src=\"https://raw.githubusercontent.com/mert-kurttutan/torchview/main/docs/images/rnn.png\" height=\"400\"/>\n\n## Show/Hide intermediate (hidden) tensors and Functionals\n\n```python\n# Show inner tensors and Functionals\nmodel_graph = draw_graph(\n    MLP(), input_size=(2, 128),\n    graph_name='MLP',\n    hide_inner_tensors=False,\n    hide_module_functions=False,\n)\n\nmodel_graph.visual_graph\n```\n\n<img src=\"https://raw.githubusercontent.com/mert-kurttutan/torchview/main/docs/images/mlp_explicit.png\" height=\"1000\"/>\n\n<!-- lstm.out -->\n\n## ResNet / Skip Connection / Support for any Torch operation\n\n```python\nimport torchvision\n\nmodel_graph = draw_graph(resnet18(), input_size=(1,3,32,32))\nmodel_graph.visual_graph\n```\n\n![](https://raw.githubusercontent.com/mert-kurttutan/torchview/main/docs/images/resnet.png \"ResnetModel\")\n\n<!-- container.out -->\n\n# Contributing\n\nAll issues and pull requests are much appreciated! If you are wondering how to build the project:\n\n- torchview is actively developed using the lastest version of Python.\n  - Changes should be backward compatible to Python 3.7, and will follow Python's End-of-Life guidance for old versions.\n  - Run `pip install -r requirements-dev.txt`. We use the latest versions of all dev packages.\n  - To run unit tests, run `pytest`.\n  - To update the expected output files, run `pytest --overwrite`.\n  - To skip output file tests, use `pytest --no-output`\n\n# References\n\n- Parts related to input processing and validation are taken/inspired from torchinfo repository!!.\n- Many of the software related parts (e.g. CI, testing) are also taken/inspired from torchinfo repository since there is a great similarity in terms of the role and structure, so big thanks to @TylerYep!!!\n- The mechanism of constructing visual graph is thanks to `__torch_function__` and subclassing torch.Tensor. Big thanks to all those who developed this API!!.\n",
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "",
            "keywords": "pytorch,visualization,keras,torch,deep learning,machine learning,ml,neural network",
            "license": "MIT License Copyright (c) 2022 Tyler Yep Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.",
            "maintainer": "",
            "maintainer_email": "Mert Kurttutan <kurttutan.mert@gmail.com>",
            "name": "torchview",
            "package_url": "https://pypi.org/project/torchview/",
            "platform": null,
            "project_url": "https://pypi.org/project/torchview/",
            "project_urls": {
                "homepage": "https://github.com/mert-kurttutan/torchview",
                "repository": "https://github.com/mert-kurttutan/torchview"
            },
            "release_url": "https://pypi.org/project/torchview/0.1.0/",
            "requires_dist": [
                "torch",
                "graphviz"
            ],
            "requires_python": ">=3.7",
            "summary": "Visualization of Pytorch Models",
            "version": "0.1.0",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 15704367,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "ad586312f72e62f8fc540597224f7a72",
                    "sha256": "b25bd2abe912001a3d5d8e8151c24be4fbf9d8e3d30254971b8feee77ecfaee3"
                },
                "downloads": -1,
                "filename": "torchview-0.1.0-py3-none-any.whl",
                "has_sig": false,
                "md5_digest": "ad586312f72e62f8fc540597224f7a72",
                "packagetype": "bdist_wheel",
                "python_version": "py3",
                "requires_python": ">=3.7",
                "size": 21917,
                "upload_time": "2022-11-08T22:53:39",
                "upload_time_iso_8601": "2022-11-08T22:53:39.691953Z",
                "url": "https://files.pythonhosted.org/packages/06/60/8a7713f133f3ff78d548edb1a4717fcac94805183493537d3034c7f305da/torchview-0.1.0-py3-none-any.whl",
                "yanked": false,
                "yanked_reason": null
            },
            {
                "comment_text": "",
                "digests": {
                    "md5": "c8affbe6777f65d214bf3007c333bbd7",
                    "sha256": "1c931fe5d38be3a0a7d7f72583463ee7eaca039ecb202156bf600a3ac51957ce"
                },
                "downloads": -1,
                "filename": "torchview-0.1.0.tar.gz",
                "has_sig": false,
                "md5_digest": "c8affbe6777f65d214bf3007c333bbd7",
                "packagetype": "sdist",
                "python_version": "source",
                "requires_python": ">=3.7",
                "size": 21489,
                "upload_time": "2022-11-08T22:53:41",
                "upload_time_iso_8601": "2022-11-08T22:53:41.855472Z",
                "url": "https://files.pythonhosted.org/packages/07/03/47daf22982b32f5c8c82e11cab2c013294750cd8b4a3d57f764feed2ce63/torchview-0.1.0.tar.gz",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    }
}
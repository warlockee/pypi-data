{
    "0.0.1a0": {
        "info": {
            "author": "tensordict contributors",
            "author_email": "vmoens@fb.com",
            "bugtrack_url": null,
            "classifiers": [],
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/pytorch-labs/tensordict",
            "keywords": "",
            "license": "BSD",
            "maintainer": "",
            "maintainer_email": "",
            "name": "tensordict",
            "package_url": "https://pypi.org/project/tensordict/",
            "platform": null,
            "project_url": "https://pypi.org/project/tensordict/",
            "project_urls": {
                "Homepage": "https://github.com/pytorch-labs/tensordict"
            },
            "release_url": "https://pypi.org/project/tensordict/0.0.1a0/",
            "requires_dist": [
                "torch",
                "numpy",
                "packaging",
                "cloudpickle",
                "torchsnapshot-nightly ; extra == 'checkpointing'",
                "pytest ; extra == 'tests'",
                "pyyaml ; extra == 'tests'",
                "pytest-instafail ; extra == 'tests'"
            ],
            "requires_python": "",
            "summary": "",
            "version": "0.0.1a0",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 16294404,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "blake2b_256": "ec7e39dae2e45ff5d10d989d18a26ff83d3f465032a6ce17c2a803b13c4f1787",
                    "md5": "36cb65fe9479eeed61f0d41c39e7ca94",
                    "sha256": "56a52ae80dcd1ef34815340d4129ad0c697b4c0a2154df4b9b86798151d35305"
                },
                "downloads": -1,
                "filename": "tensordict-0.0.1a0-py3-none-any.whl",
                "has_sig": false,
                "md5_digest": "36cb65fe9479eeed61f0d41c39e7ca94",
                "packagetype": "bdist_wheel",
                "python_version": "py3",
                "requires_python": null,
                "size": 78261,
                "upload_time": "2022-11-14T09:29:29",
                "upload_time_iso_8601": "2022-11-14T09:29:29.526917Z",
                "url": "https://files.pythonhosted.org/packages/ec/7e/39dae2e45ff5d10d989d18a26ff83d3f465032a6ce17c2a803b13c4f1787/tensordict-0.0.1a0-py3-none-any.whl",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "0.0.1b0": {
        "info": {
            "author": "tensordict contributors",
            "author_email": "vmoens@fb.com",
            "bugtrack_url": null,
            "classifiers": [
                "Programming Language :: Python :: 3.10",
                "Programming Language :: Python :: 3.7",
                "Programming Language :: Python :: 3.8",
                "Programming Language :: Python :: 3.9"
            ],
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/pytorch-labs/tensordict",
            "keywords": "",
            "license": "BSD",
            "maintainer": "",
            "maintainer_email": "",
            "name": "tensordict",
            "package_url": "https://pypi.org/project/tensordict/",
            "platform": null,
            "project_url": "https://pypi.org/project/tensordict/",
            "project_urls": {
                "Homepage": "https://github.com/pytorch-labs/tensordict"
            },
            "release_url": "https://pypi.org/project/tensordict/0.0.1b0/",
            "requires_dist": [
                "torch",
                "numpy",
                "packaging",
                "cloudpickle",
                "torchsnapshot-nightly ; extra == 'checkpointing'",
                "pytest ; extra == 'tests'",
                "pyyaml ; extra == 'tests'",
                "pytest-instafail ; extra == 'tests'"
            ],
            "requires_python": "",
            "summary": "",
            "version": "0.0.1b0",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 16294404,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "blake2b_256": "9aef005dc985f30eb772686d503059ddc38b85480c44455a812f3b0595969816",
                    "md5": "8dd0cd0a38fc9ea486dca028362ff3ec",
                    "sha256": "17c654abba548fe3fc021a37256896c8e3eab02f1ec07b5470c68023a5e16c6e"
                },
                "downloads": -1,
                "filename": "tensordict-0.0.1b0-py3-none-any.whl",
                "has_sig": false,
                "md5_digest": "8dd0cd0a38fc9ea486dca028362ff3ec",
                "packagetype": "bdist_wheel",
                "python_version": "py3",
                "requires_python": null,
                "size": 82894,
                "upload_time": "2022-12-01T00:24:54",
                "upload_time_iso_8601": "2022-12-01T00:24:54.664393Z",
                "url": "https://files.pythonhosted.org/packages/9a/ef/005dc985f30eb772686d503059ddc38b85480c44455a812f3b0595969816/tensordict-0.0.1b0-py3-none-any.whl",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "0.0.1rc0": {
        "info": {
            "author": "tensordict contributors",
            "author_email": "vmoens@fb.com",
            "bugtrack_url": null,
            "classifiers": [
                "Programming Language :: Python :: 3.10",
                "Programming Language :: Python :: 3.7",
                "Programming Language :: Python :: 3.8",
                "Programming Language :: Python :: 3.9"
            ],
            "description": "[![Documentation](https://img.shields.io/badge/Documentation-blue.svg?style=flat)](https://pytorch.org/rl/tensordict/)\n[![Python version](https://img.shields.io/pypi/pyversions/tensordict.svg)](https://www.python.org/downloads/)\n[![GitHub license](https://img.shields.io/badge/license-MIT-blue.svg)](https://github.com/pytorch-labs/tensordict/blob/main/LICENSE)\n<a href=\"https://pypi.org/project/tensordict\"><img src=\"https://img.shields.io/pypi/v/tensordict\" alt=\"pypi version\"></a>\n<a href=\"https://pypi.org/project/tensordict-nightly\"><img src=\"https://img.shields.io/pypi/v/tensordict-nightly?label=nightly\" alt=\"pypi nightly version\"></a>\n[![Downloads](https://static.pepy.tech/personalized-badge/tensordict?period=total&units=international_system&left_color=blue&right_color=orange&left_text=Downloads)](https://pepy.tech/project/tensordict)\n[![Downloads](https://static.pepy.tech/personalized-badge/tensordict-nightly?period=total&units=international_system&left_color=blue&right_color=orange&left_text=Downloads%20(nightly))](https://pepy.tech/project/tensordict-nightly)\n\n# TensorDict\n\n`TensorDict` is a dictionary-like class that inherits properties from tensors, such as indexing, shape operations, casting to device etc.\n\nThe main purpose of TensorDict is to make code-bases more _readable_ and _modular_ by abstracting away tailored operations:\n```python\nfor i, tensordict in enumerate(dataset):\n    # the model reads and writes tensordicts\n    tensordict = model(tensordict)\n    loss = loss_module(tensordict)\n    loss.backward()\n    optimizer.step()\n    optimizer.zero_grad()\n```\nWith this level of abstraction, one can recycle a training loop for highly heterogeneous task.\nEach individual step of the training loop (data collection and transform, model prediction, loss computation etc.)\ncan be tailored to the use case at hand without impacting the others.\nFor instance, the above example can be easily used across classification and segmentation tasks, among many others.\n\n## Installation\n\nTo install the latest stable version of tensordict, simply run\n```bash\npip install tensordict\n```\nThis will work with python 3.7 and upward as well as pytorch 1.12 and upward.\n\nTo enjoy the latest features, one can use\n```bash\npip install tensordict-nightly\n```\n\n## Features\n\n### General\n\nA tensordict is primarily defined by its `batch_size` (or `shape`) and its key-value pairs:\n```python\n>>> from tensordict import TensorDict\n>>> import torch\n>>> tensordict = TensorDict({\n...     \"key 1\": torch.ones(3, 4, 5),\n...     \"key 2\": torch.zeros(3, 4, 5, dtype=torch.bool),\n... }, batch_size=[3, 4])\n```\nThe `batch_size` and the first dimensions of each of the tensors must be compliant.\nThe tensors can be of any dtype and device. Optionally, one can restrict a tensordict to\nlive on a dedicated device, which will send each tensor that is written there:\n```python\n>>> tensordict = TensorDict({\n...     \"key 1\": torch.ones(3, 4, 5),\n...     \"key 2\": torch.zeros(3, 4, 5, dtype=torch.bool),\n... }, batch_size=[3, 4], device=\"cuda:0\")\n>>> tensordict[\"key 3\"] = torch.randn(3, 4, device=\"cpu\")\n>>> assert tensordict[\"key 3\"].device is torch.device(\"cuda:0\")\n```\n\n### Tensor-like features\n\nTensorDict objects can be indexed exactly like tensors. The resulting of indexing\na TensorDict is another TensorDict containing tensors indexed along the required dimension:\n```python\n>>> tensordict = TensorDict({\n...     \"key 1\": torch.ones(3, 4, 5),\n...     \"key 2\": torch.zeros(3, 4, 5, dtype=torch.bool),\n... }, batch_size=[3, 4])\n>>> sub_tensordict = tensordict[..., :2]\n>>> assert sub_tensordict.shape == torch.Size([3, 2])\n>>> assert sub_tensordict[\"key 1\"].shape == torch.Size([3, 2, 5])\n```\n\nSimilarly, one can build tensordicts by stacking or concatenating single tensordicts:\n```python\n>>> tensordicts = [TensorDict({\n...     \"key 1\": torch.ones(3, 4, 5),\n...     \"key 2\": torch.zeros(3, 4, 5, dtype=torch.bool),\n... }, batch_size=[3, 4]) for _ in range(2)]\n>>> stack_tensordict = torch.stack(tensordicts, 1)\n>>> assert stack_tensordict.shape == torch.Size([3, 2, 4])\n>>> assert stack_tensordict[\"key 1\"].shape == torch.Size([3, 2, 4, 5])\n>>> cat_tensordict = torch.cat(tensordicts, 0)\n>>> assert cat_tensordict.shape == torch.Size([6, 4])\n>>> assert cat_tensordict[\"key 1\"].shape == torch.Size([6, 4, 5])\n```\n\nTensorDict instances can also be reshaped, viewed, squeezed and unsqueezed:\n```python\n>>> tensordict = TensorDict({\n...     \"key 1\": torch.ones(3, 4, 5),\n...     \"key 2\": torch.zeros(3, 4, 5, dtype=torch.bool),\n... }, batch_size=[3, 4])\n>>> print(tensordict.view(-1))\ntorch.Size([12])\n>>> print(tensordict.reshape(-1))\ntorch.Size([12])\n>>> print(tensordict.unsqueeze(-1))\ntorch.Size([3, 4, 1])\n```\n\nOne can also send tensordict from device to device, place them in shared memory,\nclone them, update them in-place or not, split them, unbind them, expand them etc.\n\nIf a functionality is missing, it is easy to call it using `apply()` or `apply_()`:\n```python\ntensordict_uniform = tensordict.apply(lambda tensor: tensor.uniform_())\n```\n\n### TensorDict for functional programming using FuncTorch\n\nWe also provide an API to use TensorDict in conjunction with [FuncTorch](https://pytorch.org/functorch).\nFor instance, TensorDict makes it easy to concatenate model weights to do model ensembling:\n```python\n>>> from torch import nn\n>>> from tensordict import TensorDict\n>>> from tensordict.nn import make_functional\n>>> import torch\n>>> from functorch import vmap\n>>> layer1 = nn.Linear(3, 4)\n>>> layer2 = nn.Linear(4, 4)\n>>> model = nn.Sequential(layer1, layer2)\n>>> # we represent the weights hierarchically\n>>> weights1 = TensorDict(layer1.state_dict(), []).unflatten_keys(\".\")\n>>> weights2 = TensorDict(layer2.state_dict(), []).unflatten_keys(\".\")\n>>> params = make_functional(model)\n>>> assert (params == TensorDict({\"0\": weights1, \"1\": weights2}, [])).all()\n>>> # Let's use our functional module\n>>> x = torch.randn(10, 3)\n>>> out = model(x, params=params)  # params is the last arg (or kwarg)\n>>> # an ensemble of models: we stack params along the first dimension...\n>>> params_stack = torch.stack([params, params], 0)\n>>> # ... and use it as an input we'd like to pass through the model\n>>> y = vmap(model, (None, 0))(x, params_stack)\n>>> print(y.shape)\ntorch.Size([2, 10, 4])\n```\n\n### Lazy preallocation\n\nPre-allocating tensors can be cumbersome and hard to scale if the list of preallocated\nitems varies according to the script configuration. TensorDict solves this in an elegant way.\nAssume you are working with a function `foo() -> TensorDict`, e.g.\n```python\ndef foo():\n    tensordict = TensorDict({}, batch_size=[])\n    tensordict[\"a\"] = torch.randn(3)\n    tensordict[\"b\"] = TensorDict({\"c\": torch.zeros(2)}, batch_size=[])\n    return tensordict\n```\nand you would like to call this function repeatedly. You could do this in two ways.\nThe first would simply be to stack the calls to the function:\n```python\ntensordict = torch.stack([foo() for _ in range(N)])\n```\nHowever, you could also choose to preallocate the tensordict:\n```python\ntensordict = TensorDict({}, batch_size=[N])\nfor i in range(N):\n    tensordict[i] = foo()\n```\nwhich also results in a tensordict (when `N = 10`)\n```\nTensorDict(\n    fields={\n        a: Tensor(torch.Size([10, 3]), dtype=torch.float32),\n        b: TensorDict(\n            fields={\n                c: Tensor(torch.Size([10, 2]), dtype=torch.float32)},\n            batch_size=torch.Size([10]),\n            device=None,\n            is_shared=False)},\n    batch_size=torch.Size([10]),\n    device=None,\n    is_shared=False)\n```\nWhen `i==0`, your empty tensordict will automatically be populated with empty tensors\nof batch-size `N`. After that, updates will be written in-place.\nNote that this would also work with a shuffled series of indices (pre-allocation does\nnot require you to go through the tensordict in an ordered fashion).\n\n\n### Nesting TensorDicts\n\nIt is possible to nest tensordict. The only requirement is that the sub-tensordict should be indexable\nunder the parent tensordict, i.e. its batch size should match (but could be longer than) the parent\nbatch size.\n\nWe can switch easily between hierarchical and flat representations.\nFor instance, the following code will result in a single-level tensordict with keys `\"key 1\"` and `\"key 2.sub-key\"`:\n```python\n>>> tensordict = TensorDict({\n...     \"key 1\": torch.ones(3, 4, 5),\n...     \"key 2\": TensorDict({\"sub-key\": torch.randn(3, 4, 5, 6)}, batch_size=[3, 4, 5])\n... }, batch_size=[3, 4])\n>>> tensordict_flatten = tensordict.flatten_keys(separator=\".\")\n```\n\nAccessing nested tensordicts can be achieved with a single index:\n```python\n>>> sub_value = tensordict[\"key 2\", \"sub-key\"]\n```\n\n## TensorClass\n\nContent flexibility comes at the cost of predictability.\nIn some cases, developers may be looking for data structure with a more explicit behavior.\n`tensordict` provides a `dataclass`-like decorator that allows for the creation of custom dataclasses that support\nthe tensordict operations:\n```python\n>>> from tensordict.prototype import tensorclass\n>>> import torch\n>>> \n>>> @tensorclass\n... class MyData:\n...    image: torch.Tensor\n...    mask: torch.Tensor\n...    label: torch.Tensor\n...\n...    def mask_image(self):\n...        return self.image[self.mask.expand_as(self.image)].view(*self.batch_size, -1)\n...\n...    def select_label(self, label):\n...        return self[self.label == label]\n...\n>>> images = torch.randn(100, 3, 64, 64)\n>>> label = torch.randint(10, (100,))\n>>> mask = torch.zeros(1, 64, 64, dtype=torch.bool).bernoulli_().expand(100, 1, 64, 64)\n>>> \n>>> data = MyData(images, mask, label=label, batch_size=[100])\n>>>\n>>> print(data.select_label(1))\nMyData(\n    image=Tensor(torch.Size([11, 3, 64, 64]), dtype=torch.float32),\n    label=Tensor(torch.Size([11]), dtype=torch.int64),\n    mask=Tensor(torch.Size([11, 1, 64, 64]), dtype=torch.bool),\n    batch_size=torch.Size([11]),\n    device=None,\n    is_shared=False)\n>>> print(data.mask_image().shape)\ntorch.Size([100, 6117])\n>>> print(data.reshape(10, 10))\nMyData(\n    image=Tensor(torch.Size([10, 10, 3, 64, 64]), dtype=torch.float32),\n    label=Tensor(torch.Size([10, 10]), dtype=torch.int64),\n    mask=Tensor(torch.Size([10, 10, 1, 64, 64]), dtype=torch.bool),\n    batch_size=torch.Size([10, 10]),\n    device=None,\n    is_shared=False)\n```\nAs this example shows, one can write a specific data structures with dedicated methods while still enjoying the TensorDict\nartifacts such as shape operations (e.g. reshape or permutations), data manipulation (indexing, `cat` and `stack`) or calling\narbitrary functions through the `apply` method (and many more).\n\nTensorclasses support nesting and many more features.\n\n## Disclaimer\n\nTensorDict is at the alpha-stage, meaning that there may be bc-breaking changes introduced at any moment without warranty.\nHopefully that should not happen too often, as the current roadmap mostly involves adding new features and building compatibility\nwith the broader pytorch ecosystem.\n\n## License\nTorchRL is licensed under the MIT License. See [LICENSE](LICENSE) for details.\n",
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/pytorch-labs/tensordict",
            "keywords": "",
            "license": "BSD",
            "maintainer": "",
            "maintainer_email": "",
            "name": "tensordict",
            "package_url": "https://pypi.org/project/tensordict/",
            "platform": null,
            "project_url": "https://pypi.org/project/tensordict/",
            "project_urls": {
                "Homepage": "https://github.com/pytorch-labs/tensordict"
            },
            "release_url": "https://pypi.org/project/tensordict/0.0.1rc0/",
            "requires_dist": [
                "torch",
                "numpy",
                "packaging",
                "cloudpickle",
                "torchsnapshot-nightly ; extra == 'checkpointing'",
                "pytest ; extra == 'tests'",
                "pyyaml ; extra == 'tests'",
                "pytest-instafail ; extra == 'tests'"
            ],
            "requires_python": "",
            "summary": "",
            "version": "0.0.1rc0",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 16294404,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "blake2b_256": "79691f2cf9c919f3a65e41a71f2812cb923ef35de5b9d1ea5825e5cd2035774c",
                    "md5": "3db8901e592face93dc76db28712128d",
                    "sha256": "45312d4de318559e29516f332b0ffa04ad6d32aa511dd3767b53a27ad18efc20"
                },
                "downloads": -1,
                "filename": "tensordict-0.0.1rc0-py3-none-any.whl",
                "has_sig": false,
                "md5_digest": "3db8901e592face93dc76db28712128d",
                "packagetype": "bdist_wheel",
                "python_version": "py3",
                "requires_python": null,
                "size": 91780,
                "upload_time": "2023-01-03T20:02:37",
                "upload_time_iso_8601": "2023-01-03T20:02:37.988043Z",
                "url": "https://files.pythonhosted.org/packages/79/69/1f2cf9c919f3a65e41a71f2812cb923ef35de5b9d1ea5825e5cd2035774c/tensordict-0.0.1rc0-py3-none-any.whl",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    }
}